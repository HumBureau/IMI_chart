{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данный скрипт: \n",
    "\n",
    "\n",
    "## - осуществляет парсинг ежедневных чартов\n",
    "### - через API: Deezer\n",
    "### - через requests: Apple Music\n",
    "### - через selenium: VK\n",
    "#### - нужен логин и пароль (а также - пока что - запуск браузера)\n",
    "\n",
    "## - должен запускаться каждый день один раз в сутки. Самое раннее - в 11:30 утра.\n",
    "## Справка: время обновления исходных чартов.\n",
    "\n",
    "### Apple Music: 12 a.m. PST  =  10 a.m. Moscow (летом) = 11 a.m. Moscow (зимой)\n",
    "#### => обновлять в 11:30 утра по Москве\n",
    "\n",
    "### VK: 2:45 a.m Москва\n",
    "### => обновлять вместе с Apple Music\n",
    "\n",
    "\n",
    "\n",
    "## - на выходе:\n",
    "### - обновляет уже хранящиеся данные в csv файлах каждого стриминга, лежащие в корневой директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from selenium import webdriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# задаем команду для получения даты\n",
    "currentDT = datetime.now() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://music.apple.com/ru/playlist/top-100-russia/pl.728bd30a9247487c80a483f4168a9dcd'\n",
    "r = requests.get(base_url)\n",
    "sleep(randint(1,3))\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "all_texts = soup.findAll('div', attrs={'class':\"song-name-wrapper\"})\n",
    "\n",
    "a_l=[]\n",
    "s_l=[]\n",
    "\n",
    "for i in all_texts:\n",
    "    # check if empty artist name\n",
    "    if len(i.findAll('div', attrs={'class':'by-line typography-caption'})) == 0:\n",
    "        a = \"\"\n",
    "        a_l.append(a)\n",
    "    else:\n",
    "        a = i.findAll('div', attrs={'class':'by-line typography-caption'})\n",
    "        ar_l = [j.rstrip().lstrip() for j in a[0].get_text().rstrip().lstrip().split(\",\")]\n",
    "        a = \", \".join(ar_l)\n",
    "        a_l.append(a)\n",
    "    s = i.findAll('div', attrs={'class':'song-name typography-label'})[0].get_text()\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.replace(\"[\", \"\")\n",
    "    s = s.replace(\"]\", \"\")\n",
    "    s = s.strip(\" \")\n",
    "    s_l.append(s)    \n",
    "\n",
    "apple_music_top_100_daily = pd.DataFrame()\n",
    "apple_music_top_100_daily['title'] = s_l\n",
    "apple_music_top_100_daily['artist'] = a_l\n",
    "apple_music_top_100_daily['rank'] = apple_music_top_100_daily.reset_index().index +1\n",
    "apple_music_top_100_daily = apple_music_top_100_daily[['rank', 'title', 'artist']]\n",
    "\n",
    "# дата = предыдущий день (относительно дня скрейпинга)\n",
    "date = currentDT - relativedelta(days=+1)\n",
    "apple_music_top_100_daily[\"date\"] = datetime.strftime(date,\"%d/%m/%Y\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# берем имеющийся csv файл и обновляем его\n",
    "\n",
    "all_apple = pd.read_csv(\"all_apple.csv\")\n",
    "all_apple = all_apple.drop(all_apple.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_apple, apple_music_top_100_daily]\n",
    "all_apple = pd.concat(frames, sort=False)\n",
    "all_apple.to_csv(\"all_apple.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.firefox.options import Options\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [/Users/sergey/.wdm/drivers/geckodriver/macos/v0.27.0/geckodriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great, cookies worked for no-login authorisation\n"
     ]
    }
   ],
   "source": [
    "#selenium-часть\n",
    "options = Options()\n",
    "options.add_argument('-headless')\n",
    "br = webdriver.Firefox(executable_path=GeckoDriverManager().install(), options = options)\n",
    "url='https://vk.com'\n",
    "br.get(url)\n",
    "for cookie in pickle.load(open(\"vkcooks.pkl\", \"rb\")): \n",
    "    br.add_cookie(cookie) \n",
    "br.get(url)\n",
    "\n",
    "sleep(randint(2,4))\n",
    "\n",
    "if br.current_url == \"https://vk.com/feed\":\n",
    "    print(\"great, cookies worked for no-login authorisation\")\n",
    "    #now we proceed with scraping\n",
    "    \n",
    "    button2 = br.find_element_by_xpath('//*[(@id = \"l_aud\")]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"fl_l\", \" \" ))]')\n",
    "    button2.click()\n",
    "    sleep(randint(4,5))\n",
    "    button3 = br.find_element_by_css_selector('div#content li._audio_section_tab__explore > a')\n",
    "    button3.click()\n",
    "    sleep(randint(4,5))\n",
    "    button4 = br.find_element_by_css_selector('div#content div.CatalogBlock__recoms_top_audios_global_header.CatalogBlock__header > div > a')\n",
    "    button4.click()\n",
    "    sleep(randint(10,11))\n",
    "    soup = BeautifulSoup(br.page_source)\n",
    "    br.quit()\n",
    "else:\n",
    "    print(\"ERROR: please do manual login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cbb6695aaa03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"rank\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"title\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msongs_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"artist\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0martists_clean\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mvk_music_top_100_daily\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# дата = предыдущий день (относительно дня скрейпинга)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrentDT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrelativedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    433\u001b[0m             )\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         ]\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "# работаем с html\n",
    "\n",
    "songs = soup.findAll('span', attrs={'class':\"audio_row__title_inner _audio_row__title_inner\"})\n",
    "artists = soup.findAll('div', attrs={'class':\"audio_row__performers\"})\n",
    "\n",
    "songs_clean = [i.get_text() for i in songs]\n",
    "artists_clean = [i.get_text() for i in artists]\n",
    "\n",
    "data = {\"rank\": [i for i in range(1, 101)], \"title\": songs_clean, \"artist\":artists_clean}\n",
    "vk_music_top_100_daily = pd.DataFrame(data)\n",
    "# дата = предыдущий день (относительно дня скрейпинга)\n",
    "date = currentDT - relativedelta(days=+1)\n",
    "vk_music_top_100_daily[\"date\"] = datetime.strftime(date,\"%d/%m/%Y\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# берем имеющийся csv файл и обновляем его\n",
    "\n",
    "all_vk = pd.read_csv(\"all_vk.csv\")\n",
    "all_vk = all_vk.drop(all_vk.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_vk, vk_music_top_100_daily]\n",
    "all_vk = pd.concat(frames, sort=False)\n",
    "all_vk.to_csv(\"all_vk.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver_manager in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (3.2.2)\n",
      "Requirement already satisfied: crayons in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (from webdriver_manager) (0.4.0)\n",
      "Requirement already satisfied: requests in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (from webdriver_manager) (2.24.0)\n",
      "Requirement already satisfied: configparser in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (from webdriver_manager) (5.0.0)\n",
      "Requirement already satisfied: colorama in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (from crayons->webdriver_manager) (0.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (from requests->webdriver_manager) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (from requests->webdriver_manager) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (from requests->webdriver_manager) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (from requests->webdriver_manager) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.firefox import GeckoDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [/Users/sergey/.wdm/drivers/geckodriver/macos/v0.27.0/geckodriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'webdriver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b4df05b96cdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbrowser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFirefox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGeckoDriverManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://google.com/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"QuoraCookies.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'webdriver' is not defined"
     ]
    }
   ],
   "source": [
    "browser = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "browser.get('http://google.com/')\n",
    "pickle.dump(browser.get_cookies() , open(\"QuoraCookies.pkl\",\"wb\")) \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
