{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данный скрипт: \n",
    "\n",
    "\n",
    "## - осуществляет парсинг ежедневных чартов\n",
    "### - через API: Deezer\n",
    "### - через requests: Apple Music\n",
    "### - через selenium: VK\n",
    "#### - нужен логин и пароль (а также - пока что - запуск браузера)\n",
    "\n",
    "## - должен запускаться каждый день один раз в сутки. Самое раннее - в 11:30 утра.\n",
    "## Справка: время обновления исходных чартов.\n",
    "\n",
    "### Apple Music: 12 a.m. PST  =  10 a.m. Moscow (летом) = 11 a.m. Moscow (зимой)\n",
    "#### => обновлять в 11:30 утра по Москве\n",
    "\n",
    "### VK: 2:45 a.m Москва\n",
    "### => обновлять вместе с Apple Music\n",
    "\n",
    "\n",
    "\n",
    "## - на выходе:\n",
    "### - обновляет уже хранящиеся данные в csv файлах каждого стриминга, лежащие в корневой директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# задаем команду для получения даты\n",
    "currentDT = datetime.now() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://music.apple.com/us/playlist/top-100-russia/pl.728bd30a9247487c80a483f4168a9dcd'\n",
    "r = requests.get(base_url)\n",
    "sleep(randint(1,3))\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "all_texts = soup.findAll('div', attrs={'class':\"song-name-wrapper\"})\n",
    "\n",
    "a_l=[]\n",
    "s_l=[]\n",
    "\n",
    "for i in all_texts:\n",
    "    # check if empty artist name\n",
    "    if len(i.findAll('div', attrs={'class':'by-line typography-caption'})) == 0:\n",
    "        a = \"\"\n",
    "        a_l.append(a)\n",
    "    else:\n",
    "        a = i.findAll('div', attrs={'class':'by-line typography-caption'})[0].get_text()\n",
    "        a = a.replace(\"\\n\", \"\")\n",
    "        a = a.replace(\"[\", \"\")\n",
    "        a = a.replace(\"]\", \"\")\n",
    "        a = a.strip(\" \")\n",
    "        a_l.append(a)\n",
    "    s = i.findAll('div', attrs={'class':'song-name typography-label'})[0].get_text()\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.replace(\"[\", \"\")\n",
    "    s = s.replace(\"]\", \"\")\n",
    "    s = s.strip(\" \")\n",
    "    s_l.append(s)    \n",
    "\n",
    "apple_music_top_100_daily = pd.DataFrame()\n",
    "apple_music_top_100_daily['title'] = s_l\n",
    "apple_music_top_100_daily['artist'] = a_l\n",
    "apple_music_top_100_daily['rank'] = apple_music_top_100_daily.reset_index().index +1\n",
    "apple_music_top_100_daily = apple_music_top_100_daily[['rank', 'title', 'artist']]\n",
    "\n",
    "# дата = предыдущий день (относительно дня скрейпинга)\n",
    "date = currentDT - relativedelta(days=+1)\n",
    "apple_music_top_100_daily[\"date\"] = datetime.strftime(date,\"%d/%m/%Y\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# берем имеющийся csv файл и обновляем его\n",
    "\n",
    "all_apple = pd.read_csv(\"all_apple.csv\")\n",
    "all_apple = all_apple.drop(all_apple.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_apple, apple_music_top_100_daily]\n",
    "all_apple = pd.concat(frames, sort=False)\n",
    "all_apple.to_csv(\"all_apple.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium-часть\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--user-data-dir=chrome-data\")\n",
    "br = webdriver.Chrome(ChromeDriverManager().install(), options=chrome_options)\n",
    "url='https://vk.com'\n",
    "br.get(url)\n",
    "sleep(randint(2,4))\n",
    "\n",
    "if br.current_url == \"https://vk.com/feed\":\n",
    "    print(\"great, cookies worked for no-login authorisation\")\n",
    "    #now we proceed with scraping\n",
    "    \n",
    "    button2 = br.find_element_by_xpath('//*[(@id = \"l_aud\")]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"fl_l\", \" \" ))]')\n",
    "    button2.click()\n",
    "    sleep(randint(4,5))\n",
    "    button3 = br.find_element_by_css_selector('div#content li._audio_section_tab__explore > a')\n",
    "    button3.click()\n",
    "    sleep(randint(4,5))\n",
    "    button4 = br.find_element_by_css_selector('div#content div.CatalogBlock__recoms_top_audios_global_header.CatalogBlock__header > div > a')\n",
    "    button4.click()\n",
    "    sleep(randint(10,11))\n",
    "    soup = BeautifulSoup(br.page_source)\n",
    "    br.quit()\n",
    "else:\n",
    "    print(\"ERROR: please do manual login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# работаем с html\n",
    "\n",
    "songs = soup.findAll('span', attrs={'class':\"audio_row__title_inner _audio_row__title_inner\"})\n",
    "artists = soup.findAll('div', attrs={'class':\"audio_row__performers\"})\n",
    "\n",
    "songs_clean = [i.get_text() for i in songs]\n",
    "artists_clean = [i.get_text() for i in artists]\n",
    "\n",
    "data = {\"rank\": [i for i in range(1, 101)], \"title\": songs_clean, \"artist\":artists_clean}\n",
    "vk_music_top_100_daily = pd.DataFrame(data)\n",
    "# дата = предыдущий день (относительно дня скрейпинга)\n",
    "date = currentDT - relativedelta(days=+1)\n",
    "vk_music_top_100_daily[\"date\"] = datetime.strftime(date,\"%d/%m/%Y\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# берем имеющийся csv файл и обновляем его\n",
    "\n",
    "all_vk = pd.read_csv(\"all_vk.csv\")\n",
    "all_vk = all_vk.drop(all_vk.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_vk, vk_music_top_100_daily]\n",
    "all_vk = pd.concat(frames, sort=False)\n",
    "all_vk.to_csv(\"all_vk.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yy u'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"yy u\".strip(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
