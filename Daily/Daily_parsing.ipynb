{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#данный скрипт: \n",
    "\n",
    "\n",
    "## - осуществляет парсинг ежедневных чартов\n",
    "### - через API: Deezer\n",
    "### - через requests: Apple Music\n",
    "### - через selenium: VK\n",
    "#### - нужен логин и пароль (а также - пока что - запуск браузера)\n",
    "\n",
    "## - должен запускаться каждый день один раз в сутки. Самое раннее - в 11:30 утра.\n",
    "## Справка: время обновления исходных чартов.\n",
    "\n",
    "### Apple Music: 12 a.m. PST  =  10 a.m. Moscow (летом) = 11 a.m. Moscow (зимой)\n",
    "#### => обновлять в 11:30 утра по Москве\n",
    "\n",
    "### VK: 2:45 a.m Москва\n",
    "### => обновлять вместе с Apple Music\n",
    "\n",
    "### Deezer: неустановленное хаотическое время\n",
    "### => обновлять вместе с Apple Music \n",
    "\n",
    "\n",
    "\n",
    "## - на выходе:\n",
    "### - обновляет уже хранящиеся данные в csv файлах каждого стриминга, лежащие в корневой директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (from selenium) (1.25.9)\n",
      "Requirement already satisfied: chromedriver in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (2.24.1)\n"
     ]
    }
   ],
   "source": [
    "#установка и импорт selenium\n",
    "!pip install selenium\n",
    "from selenium import webdriver as wb\n",
    "!pip install chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#задаем команду для получения даты\n",
    "currentDT = datetime.datetime.now() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deezer Russia Top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "request_deezer = requests.get('https://api.deezer.com/playlist/1116189381') #ссылка на постоянный плейлист\n",
    "deezer_chart_json = request_deezer.json() #через API получаем json \n",
    "deezer_top_100_daily = pd.DataFrame(deezer_chart_json['tracks']['data']) #выбираем только список треков\n",
    "artists_deezer_top = [] #поскольку имена артистов \"запакованы\", осуществляем распаковку через цикл и заново приклеиваем к датафрейму\n",
    "for i in range(0, 100):\n",
    "    artists_deezer_top.append(deezer_chart_json['tracks']['data'][i]['artist']['name'])\n",
    "deezer_top_100_daily['artist'] = artists_deezer_top\n",
    "deezer_top_100_daily['rank'] = deezer_top_100_daily.reset_index().index +1 \n",
    "deezer_top_100_daily = deezer_top_100_daily[['rank', 'title', 'artist']]\n",
    "\n",
    "# дата = предыдущий день (относительно дня скрейпинга)\n",
    "date = currentDT \n",
    "deezer_top_100_daily[\"date\"] = datetime.datetime.strftime(date,\"%d/%m/%Y\")  \n",
    "\n",
    "# чарт этого дня готов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# берем имеющийся csv файл и обновляем его\n",
    "\n",
    "all_deezer = pd.read_csv(\"all_deezer.csv\")\n",
    "all_deezer = all_deezer.drop(all_deezer.columns[[0]], axis=1) #удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_deezer, deezer_top_100_daily]\n",
    "all_deezer = pd.concat(frames, sort=False)\n",
    "all_deezer.to_csv(\"all_deezer.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://music.apple.com/us/playlist/top-100-russia/pl.728bd30a9247487c80a483f4168a9dcd'\n",
    "r = requests.get(base_url)\n",
    "sleep(randint(1,3))\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "table = soup.findAll('div', attrs={'class':'header-and-songs-list'})\n",
    "songs = soup.findAll('div', attrs={'class':'song-name typography-label'})\n",
    "artists = soup.findAll('div', attrs={'class':'by-line typography-caption'})\n",
    "\n",
    "#чистим названия треков\n",
    "songs_clean = BeautifulSoup(str(songs), \"lxml\").text.split(\", \\n\")\n",
    "new_l=[]\n",
    "for i in songs_clean:\n",
    "    v = i.replace(\"\\n\", \"\")\n",
    "    v = v.replace(\"[\", \"\")\n",
    "    v = v.replace(\"]\", \"\")\n",
    "    v = v.strip(\" \")\n",
    "    new_l.append(v)\n",
    "songs_clean = new_l\n",
    "\n",
    "\n",
    "#чистим названия артистов\n",
    "artists_clean = BeautifulSoup(str(artists), \"lxml\").text.split(\"\\n, \\n\")\n",
    "new_l=[]\n",
    "for i in artists_clean:\n",
    "    v = i.replace(\"\\n\", \"\")\n",
    "    v = v.replace(\"[\", \"\")\n",
    "    v = v.replace(\"]\", \"\")\n",
    "    v = v.strip(\" \")\n",
    "    new_l.append(v)\n",
    "artists_clean = new_l\n",
    "\n",
    "apple_music_top_100_daily = pd.DataFrame()\n",
    "apple_music_top_100_daily['title'] = songs_clean\n",
    "apple_music_top_100_daily['artist'] = artists_clean\n",
    "\n",
    "apple_music_top_100_daily['rank'] = apple_music_top_100_daily.reset_index().index +1\n",
    "apple_music_top_100_daily = apple_music_top_100_daily[['rank', 'title', 'artist']]\n",
    "\n",
    "#дата = предыдущий день (относительно дня скрейпинга)\n",
    "date = currentDT - relativedelta(days=+1)\n",
    "apple_music_top_100_daily[\"date\"] = datetime.datetime.strftime(date,\"%d/%m/%Y\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#берем имеющийся csv файл и обновляем его\n",
    "\n",
    "all_apple = pd.read_csv(\"all_apple.csv\")\n",
    "all_apple = all_apple.drop(all_apple.columns[[0]], axis=1) #удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_apple, apple_music_top_100_daily]\n",
    "all_apple = pd.concat(frames, sort=False)\n",
    "all_apple.to_csv(\"all_apple.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium-часть\n",
    "\n",
    "url='https://vk.com'\n",
    "br = wb.Chrome()\n",
    "br.get(url)\n",
    "sleep(randint(2,4))\n",
    "e_mail_window = br.find_element_by_css_selector(\"#index_email\")\n",
    "password_window = br.find_element_by_css_selector(\"#index_pass\")\n",
    " ### ENTER LOGIN / PASSWORD ###\n",
    "login_vk = \"VKLOGIN\"\n",
    "password_vk = \"VKPASSWORD\"\n",
    " ###  ###\n",
    "e_mail_window.send_keys(login_vk)\n",
    "password_window.send_keys(password_vk)\n",
    "button1 = br.find_element_by_xpath('//*[(@id = \"index_login_button\")]')\n",
    "button1.click()\n",
    "sleep(randint(19,20))\n",
    "button2 = br.find_element_by_xpath('//*[(@id = \"l_aud\")]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"fl_l\", \" \" ))]')\n",
    "button2.click()\n",
    "sleep(randint(4,5))\n",
    "button3 = br.find_element_by_css_selector('div#content li._audio_section_tab__explore > a')\n",
    "button3.click()\n",
    "sleep(randint(4,5))\n",
    "button4 = br.find_element_by_css_selector('div#content div.CatalogBlock__recoms_top_audios_global_header.CatalogBlock__header > div > a')\n",
    "button4.click()\n",
    "sleep(randint(10,11))\n",
    "soup = BeautifulSoup(br.page_source)\n",
    "br.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#работаем с html\n",
    "\n",
    "songs = soup.findAll('span', attrs={'class':\"audio_row__title_inner _audio_row__title_inner\"})\n",
    "artists = soup.findAll('div', attrs={'class':\"audio_row__performers\"})\n",
    "\n",
    "songs_clean = [i.get_text() for i in songs]\n",
    "artists_clean = [i.get_text() for i in artists]\n",
    "\n",
    "data = {\"rank\": [i for i in range(1, 101)], \"title\": songs_clean, \"artist\":artists_clean}\n",
    "vk_music_top_100_daily = pd.DataFrame(data)\n",
    "#дата = предыдущий день (относительно дня скрейпинга)\n",
    "date = currentDT - relativedelta(days=+1)\n",
    "vk_music_top_100_daily[\"date\"] = datetime.datetime.strftime(date,\"%d/%m/%Y\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#берем имеющийся csv файл и обновляем его\n",
    "\n",
    "all_vk = pd.read_csv(\"all_vk.csv\")\n",
    "all_vk = all_vk.drop(all_vk.columns[[0]], axis=1) #удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_vk, vk_music_top_100_daily]\n",
    "all_vk = pd.concat(frames, sort=False)\n",
    "all_vk.to_csv(\"all_vk.csv\", encoding = \"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
