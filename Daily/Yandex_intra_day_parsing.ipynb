{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yandex Music - внутридневной парсинг чарта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данный скрипт:\n",
    "\n",
    "## парсит чарт яндекса весь день с периодичностью в полчаса\n",
    "\n",
    "# Время запуска скрипта: 00:30.\n",
    "\n",
    "# на выходе:\n",
    "# 1) после каждого парсинга обновляет:\n",
    "#  1.1) ВСЕ внутридневные данные -- all_yandex_intra_daily.csv\n",
    "#  1.2) внутридневные данные данного дня -- yandex_intra_daily_today.csv\n",
    "# 2) если это последний запуск (определяет по времени - если осталось меньше чем 30 минут до полуночи)...\n",
    "### ... усредняет данные (из yandex_intra_daily_today.csv !) и создает чарт яндекса за прошедший день, затем обновляет all_yandex.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from time import sleep\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg():\n",
    "    \n",
    "# усредняем данные за день и получаем чарт дня \n",
    "\n",
    "    yandex_daily_avg = pd.DataFrame(columns = ['raw_rank', 'title', 'artist', \"date\"])\n",
    "\n",
    "    df = pd.read_csv(\"yandex_intra_daily_today.csv\") \n",
    "    df[\"full_id\"] = df[\"title\"]+\"#bh#_#bh#\"+df[\"artist\"] # кодируем песню, чтобы избежать путаницы с одинаковыми названиями\n",
    "\n",
    "    for i in set(list(df[\"full_id\"])):\n",
    "        s_df = df[df[\"full_id\"]==i] # таблица с одной песней\n",
    "        l_w_ranks = list(s_df[\"rank\"])    \n",
    "        delta = n_of_scrapes - len(s_df) \n",
    "        for j in range(0,delta):\n",
    "            l_w_ranks.append(101) # присуждаем песне 101-ю строчку в те моменты, когда она не попала в чарт \n",
    "\n",
    "        avg_rank = sum(l_w_ranks)/n_of_scrapes # считаем среднюю строку песни \n",
    "        add_df = pd.DataFrame() \n",
    "        add_df[\"raw_rank\"] = [avg_rank]\n",
    "        add_df[\"title\"] = i.split(\"#bh#_#bh#\")[0]\n",
    "        add_df[\"artist\"] = i.split(\"#bh#_#bh#\")[1]\n",
    "        add_df[\"date\"] = list(s_df[\"time\"])[0].split(\" \")[0] # записываем день\n",
    "        yandex_daily_avg = yandex_daily_avg.append(add_df, ignore_index=True)\n",
    "\n",
    "    yandex_daily_avg.sort_values(by=['raw_rank'], inplace=True)\n",
    "    yandex_daily_avg['rank'] = yandex_daily_avg.reset_index().index +1\n",
    "    yandex_daily_avg.reset_index(inplace=True)\n",
    "    yandex_daily_avg.drop(yandex_daily_avg.columns[[0]], axis=1) # удаляем старый индекс\n",
    "    yandex_daily_avg.drop(yandex_daily_avg.columns[[0]], axis=1) # удаляем raw_rank\n",
    "    yandex_daily_avg=yandex_daily_avg[[\"rank\", 'title', 'artist', \"date\"]]\n",
    "    \n",
    "    # сохраняем чарт дня, обновляя базу all_yandex \n",
    "    if os.path.exists(\"all_yandex.csv\") == False:\n",
    "        yandex_daily_avg.to_csv(\"all_yandex.csv\", encoding = \"utf-8\")\n",
    "    else:\n",
    "        yandex_daily_avg.to_csv(\"all_yandex.csv\", mode='a', header = None, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# создаем словарь жанров\n",
    "try:\n",
    "    from yandex_music.client import Client\n",
    "    client = Client()\n",
    "    client = Client.from_credentials('tegusigalpa444@yandex.ru', 'aintthateasy')\n",
    "\n",
    "    gs = client.genres()\n",
    "\n",
    "    keys=[]\n",
    "    values = []\n",
    "\n",
    "    # создаем полный словарь \n",
    "    for i in range(0, len(gs)):\n",
    "        if len(gs[i].sub_genres) ==0:\n",
    "            values.append(gs[i].titles[\"ru\"][\"title\"])\n",
    "            keys.append(gs[i].id)\n",
    "        else:\n",
    "            values.append(gs[i][\"title\"])   \n",
    "            keys.append(gs[i].id)    \n",
    "            for j in range (0,len(gs[i].sub_genres)):\n",
    "                values.append(gs[i].sub_genres[j].titles[\"ru\"][\"title\"])\n",
    "                keys.append(gs[i].sub_genres[j].id)\n",
    "    d_of_genres = dict(zip(keys, values))\n",
    "    out_file = open(\"ya_genres_dict.json\", \"w\", encoding='utf8') \n",
    "    json.dump(d_of_genres, out_file, ensure_ascii=False) \n",
    "    out_file.close() \n",
    "except:\n",
    "    print(\"Error: failed to refresh genres with yandex_music.client. Using the old dictionary instead.\")\n",
    "    d_of_genres = json.load(open(\"ya_genres_dict.json\", \"r\", encoding='utf8') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get chart from API\n",
    "\n",
    "request_ya = requests.get('https://api.music.yandex.net/landing3/chart/russia') # ссылка на постоянный плейлист\n",
    "chart_json = request_ya.json() # через API получаем json \n",
    "df = pd.DataFrame(chart_json[\"result\"][\"chart\"][\"tracks\"])\n",
    "\n",
    "listeners = [int(i[\"listeners\"]) for i in  df[\"chart\"]]\n",
    "artists = [\", \".join([j[\"name\"] for j in i.get(\"artists\") or []]) for i in df[\"track\"]]\n",
    "labels = [\", \".join(j.get(\"name\") for j in i[\"albums\"][0].get(\"labels\") or []) for i in df[\"track\"]] \n",
    "songs = [i[\"title\"] for i in df[\"track\"]]\n",
    "genres = [(d_of_genres.get(i[\"albums\"][0].get(\"genre\")) or \"\") for i in df[\"track\"]]\n",
    "ranks = [int(i[\"position\"]) for i in df[\"chart\"] ]\n",
    "\n",
    "# добавляем вторичные названия (remix, OST, etc)\n",
    "add_titles = []\n",
    "for i in df[\"track\"]:\n",
    "    try:\n",
    "        add =  \" ({})\".format(i[\"version\"])\n",
    "    except:\n",
    "        add = \"\"\n",
    "    add_titles.append(add)\n",
    "songs = list(map(lambda a,b: a+b,songs, add_titles))   \n",
    "\n",
    "# Соединяем все данные в актуальный чарт\n",
    "cols = [\"rank\", \"title\", \"artist\", \"genre\", \"label\", \"listeners\"]\n",
    "DF = pd.DataFrame(dict(zip(cols, [ranks, songs, artists, genres, labels, listeners])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Экспорт \n",
    "\n",
    "#yandex_music_top_100_daily = pd.DataFrame(columns=[\"rank\", \"title\", \"artist\"])\n",
    "\n",
    "yandex_music_top_100_daily_now= DF\n",
    "yandex_music_top_100_daily_now[\"time\"] = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "# пополняем базу данных ВСЕХ внутридневных скрейпингов (просто чтобы было)\n",
    "if os.path.exists(\"all_yandex_intra_daily.csv\") == True:\n",
    "    old_csv = pd.read_csv(\"all_yandex_intra_daily.csv\")\n",
    "    old_csv = old_csv.drop(old_csv.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "    new_csv = pd.concat([old_csv,yandex_music_top_100_daily_now], ignore_index=True, sort = False)\n",
    "    new_csv.reset_index(inplace=True)\n",
    "    new_csv.drop(new_csv.columns[[0]], axis=1, inplace=True)\n",
    "    new_csv.to_csv(\"all_yandex_intra_daily.csv\", encoding = \"utf-8\")\n",
    "else:\n",
    "    yandex_music_top_100_daily_now.to_csv(\"all_yandex_intra_daily.csv\", header = None,  encoding = \"utf-8\")\n",
    "    \n",
    "\n",
    "### should we update or should we create a new csv file?\n",
    "\n",
    "if os.path.exists(\"y_nofscrapes.txt\") == True:\n",
    "    fd = os.open( \"y_nofscrapes.txt\", os.O_RDWR)\n",
    "    imp = os.read(fd,100)\n",
    "    old_n_of_scrapes = int(str(imp)[2:-1])\n",
    "    os.close( fd )\n",
    "else:\n",
    "    old_n_of_scrapes = 0\n",
    "    file = open('y_nofscrapes.txt', 'w')\n",
    "    file.write(\"0\")\n",
    "    file.close()    \n",
    "    #fd = os.open( \"y_nofscrapes.txt\", os.O_CREAT)\n",
    "    #os.write(fd, str.encode(\"0\"))\n",
    "    #os.close(fd)\n",
    "    \n",
    "# читаем сколько было скрейпингов уже   \n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "if old_n_of_scrapes == 0:\n",
    "    # сохраняем новый файл внутридневной базы данных сегодняшнего дня\n",
    "    yandex_music_top_100_daily_now.to_csv(\"yandex_intra_daily_today.csv\", encoding = \"utf-8\")\n",
    "    print(now, \"created new file for today's intradaily scrapes. another scraping round is done. more to come today.\")\n",
    "    n_of_scrapes = 1\n",
    "    fd = os.open( \"y_nofscrapes.txt\", os.O_RDWR|os.O_CREAT)\n",
    "    os.write(fd, str.encode(str(n_of_scrapes)))  \n",
    "    os.close(fd)\n",
    "else:\n",
    "    # обновляем имеющийся\n",
    "    old_csv = pd.read_csv(\"yandex_intra_daily_today.csv\")\n",
    "    old_csv = old_csv.drop(old_csv.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "    new_csv = pd.concat([old_csv,yandex_music_top_100_daily_now], ignore_index=True, sort = False)\n",
    "    new_csv.reset_index(inplace=True)\n",
    "    new_csv.drop(new_csv.columns[[0]], axis=1, inplace=True)\n",
    "    new_csv.to_csv(\"yandex_intra_daily_today.csv\", encoding = \"utf-8\")\n",
    "    \n",
    "    #yandex_music_top_100_daily_now.to_csv(\"yandex_intra_daily_today.csv\", mode=\"a\", header = None, encoding = \"utf-8\")\n",
    "    print(now, \"updated today's intradaily scrapes.\")\n",
    "    # будет ли еще хотя бы один запуск скрипта сегодня?\n",
    "    today = datetime.strftime(datetime.now(),\"%d/%m/%Y\")\n",
    "    end_time = datetime.strptime(today+ \" 23:30\", \"%d/%m/%Y %H:%M\") \n",
    "    #fd = os.open( \"y_nofscrapes.txt\", os.O_RDWR)\n",
    "    file = open('y_nofscrapes.txt', 'w')\n",
    "    n_of_scrapes = old_n_of_scrapes + 1\n",
    "    if datetime.now()>= end_time:\n",
    "        print(now, \": no more scraping for today. I am averaging the intradaily data.\")\n",
    "        # обнуляем счетчик\n",
    "        file.write(\"0\")\n",
    "        file.close()\n",
    "        #os.write(fd, str.encode(\"0\"))\n",
    "        #os.close(fd)\n",
    "        # запускаем функцию, которая усредняет все данные за день и сохраняет чарт дня\n",
    "        avg()\n",
    "        print(now, \": exported the new daily chart.\")\n",
    "    else:       \n",
    "        print(now, \": another scraping round is done. more to come today.\")\n",
    "        file.write(str(n_of_scrapes))\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
