{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#данный скрипт:\n",
    "## - высчитывает еженедельные чарты стримингов, усредняя ежедневные чарты за 7 дней \n",
    "## - стриминги: Apple Music, VK, Deezer, Yandex\n",
    "## - должен запускаться один раз в неделю утром пятницы после Youtube_parsing и Spotify_parsing\n",
    "\n",
    "## соединяет получающиеся чарты в единый html файл для публикации на сайте (включая \"настоящие\" еженедельные чарты)\n",
    "\n",
    "#на выходе:\n",
    "## - обновляет csv файлы с соответствующими еженедельными чартами 4-x стримингов\n",
    "## - сохраняет 4 html файла с новыми еженедельными чартами\n",
    "## - сохраняет 4 json файла с новыми недельными чартами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import datetime\n",
    "from datetime import datetime, date, time, timezone\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#задаем команду для получения даты\n",
    "currentDT = datetime.now() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загружаем полные базы данных по всем ежедневным чартам\n",
    "all_vk = pd.read_csv(\"all_vk.csv\")\n",
    "all_yandex = pd.read_csv(\"all_yandex.csv\")\n",
    "all_deezer = pd.read_csv(\"all_deezer.csv\")\n",
    "all_apple = pd.read_csv(\"all_apple.csv\")\n",
    "\n",
    "#загружаем базу данных по ежедневным чартам спотифая, чтобы оценивать место песен за пределами топ 100\n",
    "all_daily_spotify = pd.read_csv(\"all_daily_spotify.csv\")\n",
    "\n",
    "\n",
    "#удаляем получающуюся после импорта лишнюю колонку \n",
    "all_charts= [all_apple, all_deezer, all_vk, all_yandex]\n",
    "for i in all_charts:\n",
    "    i.drop(i.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения недельного чарта через усреднение ежедневных\n",
    "\n",
    "\n",
    "def average(df, X):\n",
    "    global not_missing_dates    \n",
    "    df['Datetime'] = [datetime.strptime(i, \"%d/%m/%Y\") for i in df[\"date\"]]\n",
    "    \n",
    "    #take last week only\n",
    "\n",
    "    last_week_df = df[date_start <= df[\"Datetime\"]]\n",
    "    df = last_week_df\n",
    "    \n",
    "    raw_rank = []\n",
    "    songs =[]\n",
    "    artists = []\n",
    "    for i in list(set(df[\"title\"])):\n",
    "        newdf = df[df[\"title\"]==i]\n",
    "        for j in list(set(newdf[\"artist\"])):\n",
    "            one_track_df = newdf[newdf[\"artist\"]==j]\n",
    "            #what dates are not missing? \n",
    "            not_missing_dates = list(one_track_df[\"date\"])\n",
    "                        \n",
    "            average_rank = (sum(one_track_df[\"rank\"]) + sum(find_avg_yaspot(i))) / 7  \n",
    "            songs.append(i)\n",
    "            artists.append(j)\n",
    "            raw_rank.append(average_rank)\n",
    "\n",
    "    data = {\"raw_rank\": raw_rank, \"title\": songs, \"artist\": artists}        \n",
    "    new_chart = pd.DataFrame(data)\n",
    "    new_chart.sort_values(by=['raw_rank'], inplace=True)\n",
    "\n",
    "    new_chart['rank'] = new_chart.reset_index().index +1\n",
    "    new_chart.reset_index(inplace=True)\n",
    "    week = datetime.strftime(date_start,\"%d/%m/%y\") + \" - \" + datetime.strftime(date_end,\"%d/%m/%y\")\n",
    "    new_chart[\"week\"] = week\n",
    "    \n",
    "    new_chart = new_chart[['rank', 'title', 'artist', \"week\", \"raw_rank\"]]\n",
    "    \n",
    "    #округляем raw_rank\n",
    "    new_chart[\"raw_rank\"] = round(new_chart[\"raw_rank\"], 3)\n",
    "    \n",
    "    return new_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#просто техническая функция для отображения изначальных имен чартов\n",
    "def name_of_global_obj(xx):\n",
    "    return [objname for objname, oid in globals().items()\n",
    "            if id(oid)==id(xx)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сделаем вспомогательные объекты для работы с датами\n",
    "all_dates = []\n",
    "for i in range(1,8):\n",
    "    k = currentDT - relativedelta(days=+i)\n",
    "    all_dates.append(datetime.strftime(k, \"%d/%m/%Y\"))\n",
    "\n",
    "date_start = currentDT - relativedelta(days=+7)\n",
    "date_end = currentDT - relativedelta(days=+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функции для поиска позиции песни, отсутствующей в данном дневном чарте, в дневных чартах яндекса и спотифай\n",
    "\n",
    "#запускается внутри average()\n",
    "\n",
    "def find_position_in_yandex(title):\n",
    "    \n",
    "    list_of_ranks =[]\n",
    "    list_of_chart_lenghts =[]\n",
    "    missing_days = list(set(all_dates) - set(not_missing_dates))\n",
    "    #print(missing_days)\n",
    "    \n",
    "    for i in missing_days:\n",
    "        day_song_df=all_yandex[all_yandex[\"date\"] == i] #CHANGE TO ALL_DAILY_YANDEX !!!!!!!!!!!!!!!\n",
    "        length_of_day_chart = len(day_song_df)\n",
    "        if title in list(day_song_df[\"title\"]):\n",
    "            #print(\"HELLO\")\n",
    "            line = day_song_df[day_song_df[\"title\"] == title]\n",
    "            rank = list(line[\"rank\"])[0]\n",
    "            list_of_ranks.append(rank)\n",
    "        else:\n",
    "            list_of_ranks.append(None)\n",
    "\n",
    "        list_of_chart_lenghts.append(length_of_day_chart)\n",
    "    \n",
    "    data = {\"date\":missing_days, \"rank_ya\":list_of_ranks, \"lengths_ya\": list_of_chart_lenghts}\n",
    "    ya_df = pd.DataFrame(data)\n",
    "    \n",
    "    return ya_df\n",
    "\n",
    "def find_position_in_spotify(title):\n",
    "    \n",
    "    list_of_ranks =[]\n",
    "\n",
    "    missing_days = list(set(all_dates) - set(not_missing_dates))\n",
    "    #print(missing_days)\n",
    "    for i in missing_days:\n",
    "        day_song_df=all_daily_spotify[all_daily_spotify[\"date\"] == i]\n",
    "        length_of_day_chart = len(day_song_df)\n",
    "        if title in list(day_song_df[\"title\"]):\n",
    "            #print(\"HELLO\")\n",
    "            line = day_song_df[day_song_df[\"title\"] == title]\n",
    "            rank = list(line[\"rank\"])[0]\n",
    "            list_of_ranks.append(rank)\n",
    "        else:\n",
    "            list_of_ranks.append(None)\n",
    "            \n",
    "    data = {\"date\":missing_days, \"rank_spot\":list_of_ranks}\n",
    "    spot_df = pd.DataFrame(data)\n",
    "    \n",
    "    return spot_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#считаем среднюю строчку за день (взвешиваем яндекс и спотифай с весами 1/2)\n",
    "\n",
    "def find_avg_yaspot(title):\n",
    "\n",
    "    \n",
    "    d1 = find_position_in_yandex(title)\n",
    "    d2 = find_position_in_spotify(title)\n",
    "    dfull = d2.combine_first(d1)\n",
    "\n",
    "    ## если в каком-то из чартов песни нет, присуждаем ей строчку сразу после последней в чарте в этот день \n",
    "    dfull[\"rank_spot\"].fillna(201, inplace=True) \n",
    "    l_of_avgs = []\n",
    "    for i in dfull.iterrows():\n",
    "        if str(i[1][\"rank_ya\"]) == \"nan\":\n",
    "            rank_ya = i[1][\"lengths_ya\"]+1\n",
    "            avg = (i[1][\"rank_spot\"]+rank_ya)/2\n",
    "        else:\n",
    "            avg = (i[1][\"rank_spot\"]+i[1][\"rank_ya\"])/2\n",
    "        l_of_avgs.append(avg)\n",
    "    \n",
    "    return l_of_avgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выполняем функцию average() и обновляем имеющиеся еженедельные чарты из csv в корне\n",
    "\n",
    "for c in all_charts:\n",
    "    \n",
    "    output_chart = average(c, 150)\n",
    "    name_of_chart = str(name_of_global_obj(c)) \n",
    "   \n",
    "\n",
    "    #обновляем csv c предыдущими еженедельными чартами\n",
    "    name_of_weekly_chart = name_of_chart +\"_weekly.csv\"\n",
    "    old_csv = pd.read_csv(name_of_weekly_chart)\n",
    "    \n",
    "    old_csv = old_csv.drop(old_csv.columns[[0]], axis=1) #удаляем получающуюся после импорта лишнюю колонку \n",
    "    frames = [old_csv, output_chart]\n",
    "    new_csv = pd.concat(frames, sort=False)\n",
    "    new_csv.to_csv(name_of_weekly_chart, encoding = \"utf-8\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление колонок, отвечающих за динамику показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загружаем все чарты, агрегированные за неделю\n",
    "all_vk_weekly = pd.read_csv(\"all_vk_weekly.csv\")\n",
    "all_yandex_weekly = pd.read_csv(\"all_yandex_weekly.csv\")\n",
    "all_deezer_weekly = pd.read_csv(\"all_deezer_weekly.csv\")\n",
    "all_apple_weekly = pd.read_csv(\"all_apple_weekly.csv\")\n",
    "\n",
    "#чистим колонки для удобства\n",
    "all_weekly_charts= [all_apple_weekly, all_deezer_weekly, all_vk_weekly, all_yandex_weekly]\n",
    "for i in all_weekly_charts:\n",
    "    try:\n",
    "        i.drop(i.columns[[0]], axis=1, inplace=True)\n",
    "        #for h in [\"weeks_in_chart\", \"best_pos\", \"full_id\", \"delta_rank\"]:\n",
    "            #i[h] = None\n",
    "    except:\n",
    "        6+8\n",
    "    i.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция для подсчета количества недель, которые песня держится в чарте\n",
    "\n",
    "def weeks_in_chart(weekly_charts):\n",
    "    \n",
    "    df = weekly_charts\n",
    "    df[\"full_id\"] = df[\"title\"]+\"#bh#_#bh#\"+df[\"artist\"] #кодируем песню, чтобы избежать путаницы с одинаковыми названиями\n",
    "\n",
    "    return_df = pd.DataFrame(columns = ['title', 'artist', \"weeks_in_chart\"])\n",
    "\n",
    "    for i in set(list(df[\"full_id\"])):\n",
    "        s_df = df[df[\"full_id\"]==i] #таблица с одной песней\n",
    "        n_of_w = len(s_df)\n",
    "        add_df = pd.DataFrame()\n",
    "        add_df[\"weeks_in_chart\"] = [n_of_w]\n",
    "        add_df[\"title\"] = i.split(\"#bh#_#bh#\")[0]\n",
    "        add_df[\"artist\"] = i.split(\"#bh#_#bh#\")[1]\n",
    "        return_df=return_df.append(add_df, ignore_index=True)\n",
    "        \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#пишем функцию, которая считает best position in chart, weeks in chart, change in rank [vs previous week]\n",
    "\n",
    "def metrics_delta(chart):\n",
    "    \n",
    "    #### best position\n",
    "    chart[\"rank\"] = chart[\"rank\"].astype(int)\n",
    "    best_pos = pd.DataFrame(chart.groupby(['title', 'artist']).agg({'rank' : 'min'}))\n",
    "    best_pos.reset_index(inplace=True)\n",
    "    best_pos.columns = ['title', 'artist', 'best_pos']\n",
    "    best_pos[\"best_pos\"] = best_pos[\"best_pos\"].astype('Int64') \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### change in rank vs previous week\n",
    "    \n",
    "    chart_last_week = chart.loc[chart['week'] == chart['week'].values[-1]] #назначаем  последнюю неделю\n",
    "    chart_dropped  = chart.drop(chart[chart['week'] == chart['week'].values[-1]].index)\n",
    "    \n",
    "    #назначаем предыдущую неделю\n",
    "    if len(chart_dropped) == 0:\n",
    "        chart_previous_week = chart.loc[chart['week'] == chart['week'].values[1]]\n",
    "    else: chart_previous_week = chart_dropped.loc[chart_dropped['week'] == chart_dropped['week'].values[-1]]\n",
    "    \n",
    "    \n",
    "    chart_previous_week = chart_previous_week[['title', 'artist', 'rank']]\n",
    "    # ! chart_upd - данные по последней неделе\n",
    "    chart_upd = pd.merge(chart_last_week, chart_previous_week, how='left', on=['title', 'artist']) \n",
    "    chart_upd['delta_rank'] = (chart_upd['rank_y'] - chart_upd['rank_x']).astype('Int64') \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #number of weeks in chart (use weeks_in_chart() function)\n",
    "    chart_upd.drop(\"weeks_in_chart\", 1, inplace = True) #avoid duplicates in columns\n",
    "    chart_upd = pd.merge(chart_upd, weeks_in_chart(chart), how='left', on=['title', 'artist'])\n",
    "    \n",
    "    \n",
    "    #присоединяем данные о best_pos \n",
    "    chart_upd.drop(\"best_pos\", 1, inplace=True)\n",
    "    new_chart = pd.merge(chart_upd, best_pos, how='left', on=['title', 'artist'])\n",
    "    chart_last_week = new_chart.loc[new_chart['week'] == new_chart['week'].values[-1]]\n",
    "    \n",
    "    #чистим\n",
    "    chart_last_week = chart_last_week.rename(columns={'rank_x': 'rank'})\n",
    "    chart_last_week.drop('rank_y', 1, inplace=True)\n",
    "    \n",
    "    \n",
    "    return chart_last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count all new metrics\n",
    "\n",
    "apple_curr_week = metrics_delta(all_apple_weekly)\n",
    "deezer_curr_week = metrics_delta(all_deezer_weekly)\n",
    "vk_curr_week = metrics_delta(all_vk_weekly)\n",
    "yandex_curr_week = metrics_delta(all_yandex_weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ЭКСПОРТ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_curr_week.name =\"apple\"\n",
    "deezer_curr_week.name =\"deezer\"\n",
    "vk_curr_week.name =\"vk\"\n",
    "yandex_curr_week.name =\"yandex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORT TO JSON, HTML, CSV \n",
    "all_curr_week_charts = [apple_curr_week, deezer_curr_week, vk_curr_week, yandex_curr_week]\n",
    "\n",
    "for ch in all_curr_week_charts:\n",
    "    \n",
    "    name_of_chart = ch.name\n",
    "    \n",
    "    ## EXPORT TO JSON ##\n",
    "    \n",
    "    with open(\"current_\" +name_of_chart+\"_json.json\", 'w', encoding='utf-8') as file:\n",
    "        ch.to_json(file, force_ascii=False)\n",
    "    \n",
    "    ## EXPORT TO CSV (i.e. MAIN DATABASE) ##\n",
    "\n",
    "    name_of_weekly_chart = \"all_\"+ name_of_chart +\"_weekly.csv\" \n",
    "    old_csv = pd.read_csv(name_of_weekly_chart)    #загружаем старые данные\n",
    "    \n",
    "    old_csv = old_csv.drop(old_csv.columns[[0]], axis=1) #удаляем получающуюся после импорта лишнюю колонку \n",
    "    frames = [old_csv, ch]\n",
    "    new_csv = pd.concat(frames, sort=False)\n",
    "    new_csv.to_csv(name_of_weekly_chart, encoding = \"utf-8\")\n",
    "    \n",
    "    ## EXPORT TO HTML ##\n",
    "    #пишем красивые названия колонок\n",
    "    ch_html = ch.drop(\"raw_rank\", 1)\n",
    "    ch_html=ch_html[[\"rank\", \"delta_rank\", \"best_pos\", \"title\", \"artist\", \"weeks_in_chart\", \"week\"]]\n",
    "    ch_html.columns = [\"Позиция\", \"Изменение позиции\", \"Лучшая позиция\", \"Название\", \"Артист\", \"Недель в чарте\", \"Неделя\"]           \n",
    "    \n",
    "    html_name = \"current_\"+name_of_chart+\"_html.html\"\n",
    "    ch_html.to_html(html_name, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
