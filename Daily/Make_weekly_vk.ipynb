{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данный скрипт:\n",
    "## - высчитывает еженедельный чарт ВК/BOOM\n",
    "## - должен запускаться один раз в неделю утром пятницы после Youtube_parsing и Spotify_parsing\n",
    "\n",
    "## соединяет получающиеся чарты в единый html файл для публикации на сайте (включая \"настоящие\" еженедельные чарты)\n",
    "\n",
    "# на выходе:\n",
    "## - обновляет csv файлы с соответствующими еженедельными чартами \n",
    "## - сохраняет html и json файл с новым еженедельным чартом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import datetime\n",
    "from datetime import datetime, date, time, timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем команду для получения даты\n",
    "currentDT = datetime.now() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем полные базы данных по всем ежедневным чартам\n",
    "all_vk = pd.read_csv(\"all_vk.csv\")\n",
    "\n",
    "all_vk.drop(all_vk.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем вспомогательные объекты для работы с датами\n",
    "all_dates = []\n",
    "for i in range(1,8):\n",
    "    k = currentDT - relativedelta(days=+i)\n",
    "    all_dates.append(datetime.strftime(k, \"%d/%m/%Y\"))\n",
    "\n",
    "date_start = currentDT - relativedelta(days=+7)\n",
    "date_end = currentDT - relativedelta(days=+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения недельного чарта через усреднение ежедневных\n",
    "\n",
    "\n",
    "def average(df):\n",
    "  \n",
    "    df['Datetime'] = [datetime.strptime(i, \"%d/%m/%Y\") for i in df[\"date\"]]\n",
    "    \n",
    "    # take last week only\n",
    "\n",
    "    last_week_df = df[date_start <= df[\"Datetime\"] ]\n",
    "    last_week_df = last_week_df[last_week_df[\"Datetime\"] <= date_end ]\n",
    "    df = last_week_df\n",
    "    \n",
    "    raw_rank = []\n",
    "    songs =[]\n",
    "    artists = []\n",
    "    for i in list(set(df[\"title\"])):\n",
    "        newdf = df[df[\"title\"]==i]\n",
    "        for j in list(set(newdf[\"artist\"])):\n",
    "            one_track_df = newdf[newdf[\"artist\"]==j]\n",
    "            # how many dates are missing? \n",
    "            not_missing_dates = list(one_track_df[\"date\"])\n",
    "            n_of_m_days = 7 - len(not_missing_dates)  \n",
    "            \n",
    "            if n_of_m_days <0:\n",
    "                print(\"Found a song with > 7 appearances in the week. Taking 7 highest ranks. Track:\", i)\n",
    "                average_rank = sum(heapq.nsmallest(7, list(one_track_df[\"rank\"]))) / 7\n",
    "            else:\n",
    "                # добавляем rank = 101 для отсутствующих дней\n",
    "                average_rank = (sum(one_track_df[\"rank\"]) + (101*n_of_m_days)) / 7 \n",
    "\n",
    "            songs.append(i)\n",
    "            artists.append(j)\n",
    "            raw_rank.append(average_rank)\n",
    "\n",
    "    data = {\"raw_rank\": raw_rank, \"title\": songs, \"artist\": artists}        \n",
    "    new_chart = pd.DataFrame(data)\n",
    "    new_chart.sort_values(by=['raw_rank'], inplace=True)\n",
    "\n",
    "    new_chart['rank'] = new_chart.reset_index().index +1\n",
    "    new_chart.reset_index(inplace=True)\n",
    "    week = datetime.strftime(date_start,\"%d/%m/%y\") + \" - \" + datetime.strftime(date_end,\"%d/%m/%y\")\n",
    "    new_chart[\"week\"] = week\n",
    "    \n",
    "    new_chart = new_chart[['rank', 'title', 'artist', \"week\", \"raw_rank\"]]\n",
    "    \n",
    "    # округляем raw_rank\n",
    "    new_chart[\"raw_rank\"] = round(new_chart[\"raw_rank\"], 3)\n",
    "    \n",
    "    return new_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просто техническая функция для отображения изначальных имен чартов\n",
    "def name_of_global_obj(xx):\n",
    "    return [objname for objname, oid in globals().items()\n",
    "            if id(oid)==id(xx)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполняем функцию average и обновляем имеющиеся еженедельные чарты из csv в корне\n",
    "\n",
    "all_simple_charts = [all_vk]\n",
    "\n",
    "for c in all_simple_charts:\n",
    "    \n",
    "    output_chart = average(c)\n",
    "    name_of_chart = str(name_of_global_obj(c)) \n",
    "   \n",
    "\n",
    "    # обновляем csv c предыдущими еженедельными чартами\n",
    "    name_of_weekly_chart = name_of_chart +\"_weekly.csv\"\n",
    "    old_csv = pd.read_csv(name_of_weekly_chart)\n",
    "    \n",
    "    old_csv = old_csv.drop(old_csv.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "    frames = [old_csv, output_chart]\n",
    "    new_csv = pd.concat(frames, sort=False, ignore_index= True)\n",
    "    #new_csv.to_csv(name_of_weekly_chart, encoding = \"utf-8\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление колонок, отвечающих за динамику показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем все чарты, агрегированные за неделю\n",
    "all_vk_weekly = new_csv\n",
    "\n",
    "# чистим колонки для удобства\n",
    "all_weekly_charts= [all_vk_weekly]\n",
    "#for i in all_weekly_charts:\n",
    "#    try:\n",
    "#        i.drop(i.columns[[0]], axis=1, inplace=True)\n",
    "        #for h in [\"weeks_in_chart\", \"best_pos\", \"full_id\", \"delta_rank\"]:\n",
    "            #i[h] = None\n",
    "#    except:\n",
    "#        6+8\n",
    "#    i.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для подсчета количества недель, которые песня держится в чарте\n",
    "\n",
    "def weeks_in_chart(weekly_charts):\n",
    "    \n",
    "    df = weekly_charts\n",
    "    df[\"title\"] = df[\"title\"].astype(str)\n",
    "    df[\"artist\"] = df[\"artist\"].astype(str)\n",
    "    df[\"full_id\"] = df[\"title\"]+\"#bh#_#bh#\"+df[\"artist\"] # кодируем песню, чтобы избежать путаницы с одинаковыми названиями\n",
    "\n",
    "    return_df = pd.DataFrame(columns = ['title', 'artist', \"weeks_in_chart\"])\n",
    "\n",
    "    for i in set(list(df[\"full_id\"])):\n",
    "        s_df = df[df[\"full_id\"]==i] # таблица с одной песней\n",
    "        n_of_w = len(s_df)\n",
    "        add_df = pd.DataFrame()\n",
    "        add_df[\"weeks_in_chart\"] = [n_of_w]\n",
    "        add_df[\"title\"] = i.split(\"#bh#_#bh#\")[0]\n",
    "        add_df[\"artist\"] = i.split(\"#bh#_#bh#\")[1]\n",
    "        return_df=return_df.append(add_df, ignore_index=True)\n",
    "        \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем функцию, которая считает best position in chart, weeks in chart, change in rank [vs previous week]\n",
    "\n",
    "def metrics_delta(chart):\n",
    "    \n",
    "    #### best position\n",
    "    chart[\"rank\"] = chart[\"rank\"].astype(int)\n",
    "    best_pos = pd.DataFrame(chart.groupby(['title', 'artist']).agg({'rank' : 'min'}))\n",
    "    best_pos.reset_index(inplace=True)\n",
    "    best_pos.columns = ['title', 'artist', 'best_pos']\n",
    "    best_pos[\"best_pos\"] = best_pos[\"best_pos\"].astype('Int64') \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### change in rank vs previous week\n",
    "    \n",
    "    chart_last_week = chart.loc[chart['week'] == chart['week'].values[-1]] # назначаем  последнюю неделю\n",
    "    chart_dropped  = chart.drop(chart[chart['week'] == chart['week'].values[-1]].index)\n",
    "    \n",
    "    # назначаем предыдущую неделю\n",
    "    if len(chart_dropped) == 0:\n",
    "        chart_previous_week = chart.loc[chart['week'] == chart['week'].values[1]]\n",
    "    else: chart_previous_week = chart_dropped.loc[chart_dropped['week'] == chart_dropped['week'].values[-1]]\n",
    "    \n",
    "    \n",
    "    chart_previous_week = chart_previous_week[['title', 'artist', 'rank']]\n",
    "    # ! chart_upd - данные по последней неделе\n",
    "    chart_upd = pd.merge(chart_last_week, chart_previous_week, how='left', on=['title', 'artist']) \n",
    "    chart_upd['delta_rank'] = (chart_upd['rank_y'] - chart_upd['rank_x']).astype('Int64') \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #number of weeks in chart (use weeks_in_chart() function)\n",
    "    chart_upd.drop(\"weeks_in_chart\", 1, inplace = True) #avoid duplicates in columns\n",
    "    chart_upd = pd.merge(chart_upd, weeks_in_chart(chart), how='left', on=['title', 'artist'])\n",
    "    \n",
    "    \n",
    "    # присоединяем данные о best_pos \n",
    "    chart_upd.drop(\"best_pos\", 1, inplace=True)\n",
    "    new_chart = pd.merge(chart_upd, best_pos, how='left', on=['title', 'artist'])\n",
    "    chart_last_week = new_chart.loc[new_chart['week'] == new_chart['week'].values[-1]]\n",
    "    \n",
    "    # чистим\n",
    "    chart_last_week = chart_last_week.rename(columns={'rank_x': 'rank'})\n",
    "    chart_last_week.drop('rank_y', 1, inplace=True)\n",
    "    \n",
    "    \n",
    "    return chart_last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count all new metrics\n",
    "\n",
    "vk_curr_week = metrics_delta(all_vk_weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ЭКСПОРТ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vk_curr_week.name =\"vk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-13 16:29:14.027546 : Exported new VK/BOOM weekly chart. Length: 112\n"
     ]
    }
   ],
   "source": [
    "### EXPORT TO JSON, HTML, CSV \n",
    "all_curr_week_charts = [vk_curr_week]\n",
    "\n",
    "\n",
    "for ch in all_curr_week_charts:\n",
    "    \n",
    "    name_of_chart = ch.name\n",
    "    \n",
    "    ## EXPORT TO JSON ##\n",
    "    \n",
    "    with open(\"current_\" +name_of_chart+\"_json.json\", 'w', encoding='utf-8') as file:\n",
    "        ch.to_json(file, force_ascii=False)\n",
    "    \n",
    "    ## EXPORT TO CSV (i.e. MAIN DATABASE) ##\n",
    "\n",
    "    name_of_weekly_chart = \"all_\"+ name_of_chart +\"_weekly.csv\" \n",
    "    old_csv = pd.read_csv(name_of_weekly_chart)    # загружаем старые данные\n",
    "    old_csv = old_csv.drop(old_csv.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "    \n",
    "    #old_csv = old_csv[:-len(ch)] # ВАЖНО: удаляем чарт этой недели, в котором еще нет новых метрик\n",
    "    \n",
    "    frames = [old_csv, ch]\n",
    "    new_csv = pd.concat(frames, sort=False, ignore_index=True)\n",
    "    new_csv.to_csv(name_of_weekly_chart, encoding = \"utf-8\")\n",
    "    \n",
    "    print(datetime.now(), \": Exported new VK/BOOM weekly chart. Length:\", len(ch))\n",
    "    \n",
    "    ## EXPORT TO HTML ##\n",
    "    # пишем красивые названия колонок\n",
    "    ch_html = ch.drop(\"raw_rank\", 1)\n",
    "    ch_html=ch_html[[\"rank\", \"delta_rank\", \"best_pos\", \"title\", \"artist\", \"weeks_in_chart\", \"week\"]]\n",
    "    ch_html.columns = [\"Позиция\", \"Изменение позиции\", \"Лучшая позиция\", \"Название\", \"Артист\", \"Недель в чарте\", \"Неделя\"]           \n",
    "    \n",
    "    html_name = \"current_\"+name_of_chart+\"_html.html\"\n",
    "    ch_html.to_html(html_name, encoding = \"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
