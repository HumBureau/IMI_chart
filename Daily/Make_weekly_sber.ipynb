{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данный скрипт:\n",
    "## - высчитывает еженедельные чарты сбера, усредняя ежедневные чарты за 7 дней \n",
    "## - стриминги: СБЕРЗВУК\n",
    "## - должен запускаться один раз в неделю утром пятницы (можно хоть в 00:01)\n",
    "\n",
    "# на выходе:\n",
    "## - csv, json с актуальным недельным чартом\n",
    "## - html с актуальным недельным чартом и аккуратными подписями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import datetime\n",
    "from datetime import datetime, date, time, timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем команду для получения даты\n",
    "currentDT = datetime.now() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем полные базы данных по всем ежедневным чартам\n",
    "all_sber = pd.read_csv(\"all_sber.csv\")\n",
    "\n",
    "# удаляем получающуюся после импорта лишнюю колонку \n",
    "all_charts= [all_sber]\n",
    "for i in all_charts:\n",
    "    i.drop(i.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем вспомогательные объекты для работы с датами\n",
    "all_dates = []\n",
    "for i in range(1,8):\n",
    "    k = currentDT - relativedelta(days=+i)\n",
    "    all_dates.append(datetime.strftime(k, \"%d/%m/%Y\"))\n",
    "\n",
    "date_start = currentDT - relativedelta(days=+7)\n",
    "date_end = currentDT - relativedelta(days=+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения недельного чарта через усреднение ежедневных\n",
    "# только для apple, deezer, VK\n",
    "\n",
    "\n",
    "def average(df):\n",
    "  \n",
    "    df['Datetime'] = [datetime.strptime(i, \"%d/%m/%Y\") for i in df[\"date\"]]\n",
    "    \n",
    "    # take last week only\n",
    "\n",
    "    last_week_df = df[date_start <= df[\"Datetime\"]]\n",
    "    df = last_week_df\n",
    "    \n",
    "    raw_rank = []\n",
    "    songs =[]\n",
    "    artists = []\n",
    "    for i in list(set(df[\"title\"])):\n",
    "        newdf = df[df[\"title\"]==i]\n",
    "        for j in list(set(newdf[\"artist\"])):\n",
    "            one_track_df = newdf[newdf[\"artist\"]==j]\n",
    "            # how many dates are missing? \n",
    "            not_missing_dates = list(one_track_df[\"date\"])\n",
    "            n_of_m_days = 7 - len(not_missing_dates)            \n",
    "            # добавляем rank = 101 для отсутствующих дней\n",
    "            average_rank = (sum(one_track_df[\"rank\"]) + (101*n_of_m_days)) / 7  \n",
    "            songs.append(i)\n",
    "            artists.append(j)\n",
    "            raw_rank.append(average_rank)\n",
    "\n",
    "    data = {\"raw_rank\": raw_rank, \"title\": songs, \"artist\": artists}        \n",
    "    new_chart = pd.DataFrame(data)\n",
    "    new_chart.sort_values(by=['raw_rank'], inplace=True)\n",
    "\n",
    "    new_chart['rank'] = new_chart.reset_index().index +1\n",
    "    new_chart.reset_index(inplace=True)\n",
    "    week = datetime.strftime(date_start,\"%d/%m/%y\") + \" - \" + datetime.strftime(date_end,\"%d/%m/%y\")\n",
    "    new_chart[\"week\"] = week\n",
    "    \n",
    "    new_chart = new_chart[['rank', 'title', 'artist', \"week\", \"raw_rank\"]]\n",
    "    \n",
    "    # округляем raw_rank\n",
    "    new_chart[\"raw_rank\"] = round(new_chart[\"raw_rank\"], 3)\n",
    "    \n",
    "    return new_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просто техническая функция для отображения изначальных имен чартов\n",
    "def name_of_global_obj(xx):\n",
    "    return [objname for objname, oid in globals().items()\n",
    "            if id(oid)==id(xx)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем недельные чарты для VK, Apple, Deezer\n",
    "# выполняем функцию average и обновляем имеющиеся еженедельные чарты из csv в корне\n",
    "\n",
    "all_simple_charts = [all_sber]\n",
    "\n",
    "for c in all_simple_charts:\n",
    "    \n",
    "    output_chart = average(c)\n",
    "    name_of_chart = str(name_of_global_obj(c)) \n",
    "   \n",
    "\n",
    "    # обновляем csv c предыдущими еженедельными чартами\n",
    "    name_of_weekly_chart = name_of_chart +\"_weekly.csv\"\n",
    "    if path.exists(name_of_weekly_chart):\n",
    "        old_csv = pd.read_csv(name_of_weekly_chart)\n",
    "        old_csv = old_csv.drop(old_csv.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "        frames = [old_csv, output_chart] \n",
    "        new_csv = pd.concat(frames, sort=False)\n",
    "    else:\n",
    "        new_csv = output_chart\n",
    "    new_csv.to_csv(name_of_weekly_chart, encoding = \"utf-8\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление колонок, отвечающих за динамику показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем все чарты, агрегированные за неделю\n",
    "all_sber_weekly = pd.read_csv(\"all_sber_weekly.csv\")\n",
    "\n",
    "\n",
    "# чистим колонки для удобства\n",
    "all_weekly_charts= [all_sber_weekly]\n",
    "for i in all_weekly_charts:\n",
    "    try:\n",
    "        i.drop(i.columns[[0]], axis=1, inplace=True)\n",
    "        # add missing columns (if they are missing)\n",
    "        for h in [\"weeks_in_chart\", \"best_pos\", \"full_id\", \"delta_rank\"]:\n",
    "            if h in i.columns:\n",
    "                7+9\n",
    "            else:\n",
    "                i[h]=None\n",
    "    except:\n",
    "        6+8\n",
    "    i.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для подсчета количества недель, которые песня держится в чарте\n",
    "\n",
    "def weeks_in_chart(weekly_charts):\n",
    "    \n",
    "    df = weekly_charts\n",
    "    df[\"title\"] = df[\"title\"].astype(str)\n",
    "    df[\"artist\"] = df[\"artist\"].astype(str)\n",
    "    df[\"full_id\"] = df[\"title\"]+\"#bh#_#bh#\"+df[\"artist\"] # кодируем песню, чтобы избежать путаницы с одинаковыми названиями\n",
    "\n",
    "    return_df = pd.DataFrame(columns = ['title', 'artist', \"weeks_in_chart\"])\n",
    "\n",
    "    for i in set(list(df[\"full_id\"])):\n",
    "        s_df = df[df[\"full_id\"]==i] # таблица с одной песней\n",
    "        n_of_w = len(s_df)\n",
    "        add_df = pd.DataFrame()\n",
    "        add_df[\"weeks_in_chart\"] = [n_of_w]\n",
    "        add_df[\"title\"] = i.split(\"#bh#_#bh#\")[0]\n",
    "        add_df[\"artist\"] = i.split(\"#bh#_#bh#\")[1]\n",
    "        return_df=return_df.append(add_df, ignore_index=True)\n",
    "        \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем функцию, которая считает best position in chart, weeks in chart, change in rank [vs previous week]\n",
    "\n",
    "def metrics_delta(chart):\n",
    "    \n",
    "    #### best position\n",
    "    chart[\"rank\"] = chart[\"rank\"].astype(int)\n",
    "    best_pos = pd.DataFrame(chart.groupby(['title', 'artist']).agg({'rank' : 'min'}))\n",
    "    best_pos.reset_index(inplace=True)\n",
    "    best_pos.columns = ['title', 'artist', 'best_pos']\n",
    "    best_pos[\"best_pos\"] = best_pos[\"best_pos\"].astype('Int64') \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### change in rank vs previous week\n",
    "    \n",
    "    chart_last_week = chart.loc[chart['week'] == chart['week'].values[-1]] # назначаем  последнюю неделю\n",
    "    chart_dropped  = chart.drop(chart[chart['week'] == chart['week'].values[-1]].index)\n",
    "    \n",
    "    # назначаем предыдущую неделю\n",
    "    if len(chart_dropped) == 0:\n",
    "        chart_previous_week = chart.loc[chart['week'] == chart['week'].values[1]]\n",
    "    else: chart_previous_week = chart_dropped.loc[chart_dropped['week'] == chart_dropped['week'].values[-1]]\n",
    "    \n",
    "    \n",
    "    chart_previous_week = chart_previous_week[['title', 'artist', 'rank']]\n",
    "    # ! chart_upd - данные по последней неделе\n",
    "    chart_upd = pd.merge(chart_last_week, chart_previous_week, how='left', on=['title', 'artist']) \n",
    "    chart_upd['delta_rank'] = (chart_upd['rank_y'] - chart_upd['rank_x']).astype('Int64') \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #number of weeks in chart (use weeks_in_chart() function)\n",
    "    chart_upd.drop(\"weeks_in_chart\", 1, inplace = True) #avoid duplicates in columns\n",
    "    chart_upd = pd.merge(chart_upd, weeks_in_chart(chart), how='left', on=['title', 'artist'])\n",
    "    \n",
    "    \n",
    "    # присоединяем данные о best_pos \n",
    "    chart_upd.drop(\"best_pos\", 1, inplace=True)\n",
    "    new_chart = pd.merge(chart_upd, best_pos, how='left', on=['title', 'artist'])\n",
    "    chart_last_week = new_chart.loc[new_chart['week'] == new_chart['week'].values[-1]]\n",
    "    \n",
    "    # чистим\n",
    "    chart_last_week = chart_last_week.rename(columns={'rank_x': 'rank'})\n",
    "    chart_last_week.drop('rank_y', 1, inplace=True)\n",
    "    \n",
    "    \n",
    "    return chart_last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count all new metrics\n",
    "\n",
    "sber_curr_week = metrics_delta(all_sber_weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ЭКСПОРТ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sber_curr_week.name =\"sber\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORT TO JSON, HTML, CSV \n",
    "all_curr_week_charts = [sber_curr_week]\n",
    "\n",
    "for ch in all_curr_week_charts:\n",
    "    \n",
    "    name_of_chart = ch.name\n",
    "    \n",
    "    ## EXPORT TO JSON ##\n",
    "    \n",
    "    with open(\"current_\" +name_of_chart+\"_json.json\", 'w', encoding='utf-8') as file:\n",
    "        ch.to_json(file, force_ascii=False)\n",
    "    \n",
    "    ## EXPORT TO CSV (i.e. MAIN DATABASE) ##\n",
    "\n",
    "    name_of_weekly_chart = \"all_\"+ name_of_chart +\"_weekly.csv\" \n",
    "    old_csv = pd.read_csv(name_of_weekly_chart)    # загружаем старые данные\n",
    "    \n",
    "    old_csv = old_csv.drop(old_csv.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "    frames = [old_csv, ch]\n",
    "    new_csv = pd.concat(frames, sort=False)\n",
    "    new_csv.to_csv(name_of_weekly_chart, encoding = \"utf-8\")\n",
    "    \n",
    "    ## EXPORT TO HTML ##\n",
    "    # пишем красивые названия колонок\n",
    "    ch_html = ch.drop(\"raw_rank\", 1)\n",
    "    ch_html=ch_html[[\"rank\", \"delta_rank\", \"best_pos\", \"title\", \"artist\", \"weeks_in_chart\", \"week\"]]\n",
    "    ch_html.columns = [\"Позиция\", \"Изменение позиции\", \"Лучшая позиция\", \"Название\", \"Артист\", \"Недель в чарте\", \"Неделя\"]           \n",
    "    \n",
    "    html_name = \"current_\"+name_of_chart+\"_html.html\"\n",
    "    ch_html.to_html(html_name, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
