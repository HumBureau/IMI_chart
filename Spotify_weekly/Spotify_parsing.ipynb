{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данный скрипт: \n",
    "\n",
    "## - осуществляет парсинг еженедельного чарта Spotify Top 200 Russia\n",
    "\n",
    "## время запуска: утро пятницы\n",
    "## период чарта: пятница-четверг\n",
    "\n",
    "## - на выходе:\n",
    "### - обновляет уже хранящиеся данные прошлых недель в csv \n",
    "### - сохраняет html файл актуального чарта для демонстрации на сайте\n",
    "### - сохраняет json актуального чарта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import datetime\n",
    "from datetime import datetime, date, time, timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "currentDT = datetime.now() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# авторизуемся в API спотифая\n",
    "\n",
    "client_id = 'ab06777876f4480c945208f0d0d16160'\n",
    "client_secret = 'e02805f2372249f1afe66ec7b3d6e20a'\n",
    "username = \"11158413093\"\n",
    "scope = \"playlist-modify-public\"\n",
    "playlist_id = \"6n485XL3OjM56Lwax8LVQb\"\n",
    "redirect_uri='http://localhost:8080'\n",
    "CACHE = '.spotipyoauthcache'\n",
    "\n",
    "\n",
    "### SP - это объект, который занимается авторизацией\n",
    "SP = spotipy.oauth2.SpotifyPKCE(client_id=client_id, redirect_uri=redirect_uri, scope=scope, username=username, cache_path = CACHE, proxies=None, requests_timeout=None, requests_session=True, open_browser=False)\n",
    "\n",
    "\n",
    "### смело пробуем получить новый access token просто через refresh token, лежащий в кэше\n",
    "# 1 берем refresh token \n",
    "refr_t = SP.get_cached_token()[\"refresh_token\"]\n",
    "# 2 рефрешим access token\n",
    "try:\n",
    "    SP.refresh_access_token(refresh_token=refr_t)\n",
    "    print(datetime.now(), \": \", \"Refreshed access token OK.\")\n",
    "except Exception as e:\n",
    "    print(datetime.now(), \": \", e)\n",
    "\n",
    "### sp - это объект, который занимается управлением (редактированием плейлистов и т.д.)\n",
    "sp = spotipy.Spotify(auth = SP.get_access_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция, которая собирает данные из spotifycharts, включая ссылки на треки\n",
    "def scrape(d):\n",
    "############################## Сам парсинг #############################\n",
    "\n",
    "    # базовая ссылка на последний актуальный еженедельный чарт по России\n",
    "    base_url = 'https://spotifycharts.com/regional/ru/weekly/'+d\n",
    "    r = requests.get(base_url)\n",
    "    # на всякий случай поставим на паузу\n",
    "    sleep(2)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    chart = soup.find('table', {'class': 'chart-table'})\n",
    "    wt = 2\n",
    "    \n",
    "    # цикл на случай, если не загрузилось\n",
    "    while len(chart) == 0:\n",
    "        wt = wt+2\n",
    "        r = requests.get(base_url)\n",
    "        sleep(wt)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        chart = soup.find('table', {'class': 'chart-table'})\n",
    "        \n",
    "    tbody = chart.find('tbody')\n",
    "    all_rows = []\n",
    "\n",
    "\n",
    "    # сам скрэйпинг\n",
    "    for tr in tbody.find_all('tr'):\n",
    "        # позиция трека\n",
    "        rank_text = tr.find('td', {'class': 'chart-table-position'}).text\n",
    "        # ссылка на трек\n",
    "        link_text = tr.a.get(\"href\")\n",
    "        # название трека\n",
    "        title_text = tr.find('td', {'class': 'chart-table-track'}).find('strong').text\n",
    "        # кол-во стримов для трека\n",
    "        streams_text = tr.find('td', {'class': 'chart-table-streams'}).text\n",
    "        #cборка таблицы (цикл на случай парсинга нескольких чартов)\n",
    "        all_rows.append( [rank_text, link_text, title_text, streams_text] )\n",
    "\n",
    "    # создаем читаемый датафрейм в pandas\n",
    "    rus_spotify_top_200 = pd.DataFrame(all_rows, columns =['rank','link', \"title\",'streams'])\n",
    "\n",
    "    #date = дата скрейпинга!\n",
    "    #rus_spotify_top_200[\"date\"] = currentDT.strftime(\"%d/%m/%Y\")  \n",
    "\n",
    "    # записываем неделю \n",
    "    #date_start = currentDT - relativedelta(days=+7)\n",
    "    #date_end = currentDT - relativedelta(days=+1)\n",
    "    #week = datetime.strftime(date_start,\"%d/%m/%y\") + \" - \" + datetime.strftime(date_end,\"%d/%m/%y\")\n",
    "    week = d\n",
    "    rus_spotify_top_200[\"week\"] = week\n",
    "\n",
    "\n",
    "    now = datetime.now()\n",
    "\n",
    "    print(now, \": scraped the new chart. length of data:\", len(rus_spotify_top_200))\n",
    "    \n",
    "    return rus_spotify_top_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_25_artists(I):\n",
    "\n",
    "\n",
    "    url = \"https://open.spotify.com/playlist/\"+I\n",
    "\n",
    "\n",
    "    options = Options()\n",
    "    options.add_argument('-headless')\n",
    "\n",
    "    profile = webdriver.FirefoxProfile()\n",
    "    profile.set_preference('intl.accept_languages', 'rus-RUS, ru')\n",
    "    profile.set_preference('media.gmp-manager.updateEnabled', True)\n",
    "\n",
    "    br = webdriver.Firefox(executable_path=GeckoDriverManager().install(), firefox_profile=profile, options = options)\n",
    "\n",
    "    br.get(url)\n",
    "\n",
    "\n",
    "    sleep(5)\n",
    "\n",
    "    soup = bs(br.page_source, parser = \"lxml\")\n",
    "    \n",
    "    H = soup.find_all(\"span\", {\"class\":\"_966e29b71d2654743538480947a479b3-scss\"})\n",
    "    i_l = []\n",
    "    for h in H:\n",
    "        i_l.append(h.get_text())\n",
    "    \n",
    "    br.quit()\n",
    "        \n",
    "    return i_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем ссылку на нужную неделю\n",
    "\n",
    "# дата начала \n",
    "cor_m_dates = [datetime(2020, 7, 10, 0, 0)]\n",
    "\n",
    "while cor_m_dates[-1] +relativedelta(days = +7) <= datetime.now():\n",
    "    cor_m_dates.append(cor_m_dates[-1] +relativedelta(days = +7))\n",
    "\n",
    "if cor_m_dates[-1] +relativedelta(days = +7) > datetime.now():\n",
    "    cor_m_dates=cor_m_dates[:-1]\n",
    "    \n",
    "curr_date_start = cor_m_dates[-1]\n",
    "w_f_link = datetime.strftime(curr_date_start, \"%Y-%m-%d\")+\"--\"+datetime.strftime(curr_date_start+relativedelta(days = +7), \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame(columns = [\"rank\", \"title\", \"artist\", \"streams\", \"week\", \"link\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сбор имен артистов через добавление треков из топ-200 в плейлист партиями по 25 треков\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # скрейпим spotifycharts\n",
    "        curr_df = scrape(w_f_link)\n",
    "        links = list(curr_df[\"link\"])\n",
    "        id_list=[]\n",
    "        A_L = []\n",
    "        for L in links:\n",
    "            id_list.append(L.split(\"/\")[-1])\n",
    "            if len(id_list) == 25:\n",
    "                #print(id_list)\n",
    "                sp.user_playlist_add_tracks(username, playlist_id = playlist_id, tracks = id_list, position=None)\n",
    "                A_L.extend(get_25_artists(playlist_id))\n",
    "                # clear playlist\n",
    "                sp.user_playlist_remove_all_occurrences_of_tracks(username, playlist_id=playlist_id, tracks = id_list, snapshot_id=None)\n",
    "                # clear list \n",
    "                s_id_list = id_list\n",
    "                id_list = []\n",
    "                #print(len(A_L), A_L)\n",
    "\n",
    "        curr_df[\"artist\"] = A_L\n",
    "        print(datetime.now(), \": Added correct artist names\")\n",
    "\n",
    "        curr_df=curr_df[[\"rank\", \"title\", \"artist\", \"streams\", \"week\", \"link\"]]\n",
    "\n",
    "        frames = [full_df, curr_df]\n",
    "        full_df=pd.concat(frames, sort=False)\n",
    "\n",
    "        full_df.reset_index(inplace=True)\n",
    "        full_df.drop(full_df.columns[[0]], axis=1, inplace=True)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(datetime.now(), \": \", e)\n",
    "        sp.user_playlist_remove_all_occurrences_of_tracks(username, playlist_id=playlist_id, tracks = s_id_list, snapshot_id=None)\n",
    "        sleep(3600)\n",
    "        token = util.prompt_for_user_token(username,scope,client_id=client_id,client_secret=client_secret,redirect_uri='http://localhost/') \n",
    "        sp = spotipy.Spotify(auth = token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем запятые в числах\n",
    "\n",
    "n_s = []\n",
    "for i in full_df[\"streams\"]:\n",
    "    h = int(\"\".join(i.split(\",\")))\n",
    "    n_s.append(h)\n",
    "\n",
    "full_df[\"streams\"] = n_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ФОРМИРУЕМ ПОЛНЫЙ ЧАРТ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для подсчета количества недель, которые песня держится в чарте\n",
    "\n",
    "def weeks_in_chart(weekly_charts):\n",
    "    \n",
    "    df = weekly_charts\n",
    "    df[\"full_id\"] = df[\"title\"]+\"#bh#_#bh#\"+df[\"artist\"] # кодируем песню, чтобы избежать путаницы с одинаковыми названиями\n",
    "\n",
    "    return_df = pd.DataFrame(columns = ['title', 'artist', \"weeks_in_chart\"])\n",
    "\n",
    "    for i in set(list(df[\"full_id\"])):\n",
    "        s_df = df[df[\"full_id\"]==i] # таблица с одной песней\n",
    "        n_of_w = len(s_df)\n",
    "        add_df = pd.DataFrame()\n",
    "        add_df[\"weeks_in_chart\"] = [n_of_w]\n",
    "        add_df[\"title\"] = i.split(\"#bh#_#bh#\")[0]\n",
    "        add_df[\"artist\"] = i.split(\"#bh#_#bh#\")[1]\n",
    "        return_df=return_df.append(add_df, ignore_index=True)\n",
    "        \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем функцию, которая считает best position in chart, weeks in chart, change in rank [vs previous week]\n",
    "\n",
    "def metrics_delta(chart):\n",
    "    \n",
    "    chart.reset_index(inplace=True)\n",
    "    chart.drop(\"index\", axis = 1, inplace = True)\n",
    "    \n",
    "    #### best position\n",
    "    chart[\"rank\"] = chart[\"rank\"].astype(int)\n",
    "    best_pos = pd.DataFrame(chart.groupby(['title', 'artist']).agg({'rank' : 'min'}))\n",
    "    best_pos.reset_index(inplace=True)\n",
    "    best_pos.columns = ['title', 'artist', 'best_pos']\n",
    "    best_pos[\"best_pos\"] = best_pos[\"best_pos\"].astype('Int64') \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### change in rank vs previous week\n",
    "    # назначаем  последнюю (т.е. актуальную) неделю\n",
    "    \n",
    "    chart_last_week = chart.loc[chart['week'] == chart['week'].values[-1]] \n",
    "    chart_dropped  = chart.drop(chart[chart['week'] == chart['week'].values[-1]].index)\n",
    "    \n",
    "    # назначаем предпоследнюю (т.е. предыдущую) неделю\n",
    "    if len(chart_dropped) == 0:\n",
    "        chart_previous_week = chart.loc[chart['week'] == chart['week'].values[1]]\n",
    "    else: \n",
    "        chart_previous_week = chart_dropped.loc[chart_dropped['week'] == chart_dropped['week'].values[-1]]\n",
    "    chart_previous_week = chart_previous_week[['title', 'artist', 'rank']]\n",
    "    \n",
    "    # ! chart_upd - это датафрейм, который мы строим\n",
    "    chart_upd = pd.merge(chart_last_week, chart_previous_week, how='left', on=['title', 'artist']) \n",
    "    chart_upd['delta_rank'] = (chart_upd['rank_y'] - chart_upd['rank_x']).astype('Int64') \n",
    "    \n",
    "    #number of weeks in chart (use weeks_in_chart() function)\n",
    "    chart_upd.drop(\"weeks_in_chart\", 1, inplace = True) #avoid duplicates in columns\n",
    "    chart_upd = pd.merge(chart_upd, weeks_in_chart(chart), how='left', on=['title', 'artist'])\n",
    "    \n",
    "    \n",
    "    # присоединяем данные о best_pos \n",
    "    chart_upd.drop(\"best_pos\", 1, inplace=True)\n",
    "    new_chart = pd.merge(chart_upd, best_pos, how='left', on=['title', 'artist'])\n",
    "    chart_last_week = new_chart.loc[new_chart['week'] == new_chart['week'].values[-1]]\n",
    "    \n",
    "    # чистим\n",
    "    chart_last_week = chart_last_week.rename(columns={'rank_x': 'rank'})\n",
    "    chart_last_week.drop('rank_y', 1, inplace=True)\n",
    "    \n",
    "    \n",
    "    return chart_last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для подсчета изменения прослушиваний\n",
    "def streams_delta_spot(chart): \n",
    "    \n",
    "    try:\n",
    "        chart['streams'] = chart['streams'].astype(str).str.replace(\",\", \"\").astype(int)\n",
    "    except:\n",
    "        5+3\n",
    "        \n",
    "    chart_last_week = chart[chart['week'] == chart['week'].values[-1]]\n",
    "    chart_dropped  = chart.drop(chart[chart['week'] == chart['week'].values[-1]].index)\n",
    "    if len(chart_dropped) == 0:\n",
    "        chart_previous_week = chart.loc[chart['week'] == chart['week'].values[1]]\n",
    "    else: \n",
    "        chart_previous_week = chart_dropped.loc[chart_dropped['week'] == chart_dropped['week'].values[-1]]\n",
    "    chart_previous_week = chart_previous_week[['title', 'artist', 'streams']]\n",
    "    chart_upd = pd.merge(chart_last_week, chart_previous_week, how='left', on=['title', 'artist'])\n",
    "    #chart_upd[\"streams_y\"].fillna(0, inplace=True)\n",
    "    chart_upd['delta_streams'] = (chart_upd['streams_x'] - chart_upd['streams_y']).astype('Int64')\n",
    "    chart_upd = chart_upd[['title', 'artist', 'delta_streams']]\n",
    "    \n",
    "    return chart_upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"all_spotify.csv\") == False:\n",
    "    df = pd.DataFrame(columns=['rank', 'title', 'artist', 'date', 'streams', 'week',\n",
    "                               'delta_rank', 'weeks_in_chart', 'best_pos', 'delta_streams', 'full_id', \"week_f_show\"])\n",
    "    df.to_csv(\"all_spotify.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# соединяем старые данные с новыми (но пока без экспорта)\n",
    "\n",
    "all_spotify = pd.read_csv(\"all_spotify.csv\")\n",
    "\n",
    "all_spotify = all_spotify.drop(all_spotify.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [all_spotify, curr_df]\n",
    "all_spotify = pd.concat(frames, sort=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подсчитываем все дополнительные показатели\n",
    "sp1 = streams_delta_spot(all_spotify) # count delta_streams\n",
    "spotify_curr_week = metrics_delta(all_spotify) # count other metrics\n",
    "spotify_curr_week.drop(\"delta_streams\", 1, inplace=True) # drop so that columns don't duplicate\n",
    "\n",
    "# merge delta_streams and other metrics\n",
    "spotify_curr_week = pd.merge(spotify_curr_week, sp1, how='left', on=['title', 'artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# добавляем настоящие названия недель (а не те, что в ссылках)\n",
    "\n",
    "w = spotify_curr_week[\"week\"][0]\n",
    "ed = datetime.strptime(w[-10:], \"%Y-%m-%d\") - relativedelta(days=+1)\n",
    "sd = datetime.strptime(w[:10], \"%Y-%m-%d\") \n",
    "w_f_show = datetime.strftime(sd,  \"%d-%m-%y\")+\" - \"+datetime.strftime(ed,  \"%d-%m-%y\")\n",
    "spotify_curr_week[\"week_f_show\"] = w_f_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ЭКСПОРТ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORT TO JSON\n",
    "with open('current_spotify_json.json', 'w', encoding='utf-8') as file:\n",
    "    spotify_curr_week.to_json(file, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORT TO HTML\n",
    "# сохраняем html для использования на сайте (т.е. через Make_weekly_charts.py впоследствии)\n",
    "spotify_curr_week_html=spotify_curr_week[[\"rank\", \"delta_rank\", \"best_pos\", \"title\", \"artist\", \"streams\", \"delta_streams\", \"weeks_in_chart\", \"week_f_show\"]]\n",
    "spotify_curr_week_html.columns = [\"Позиция\", \"Изменение позиции\", \"Лучшая позиция\", \"Название\", \"Артист\", \"Прослушивания\", \"Динамика прослушиваний\", \"Недель в чарте\", \"Неделя\"]\n",
    "spotify_curr_week_html.to_html(\"current_spotify_html.html\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORT TO CSV - (i.e. TO THE MAIN DATABASE)\n",
    "# берем имеющийся в корневой директории csv файл и обновляем его\n",
    "\n",
    "all_spotify = pd.read_csv(\"all_spotify.csv\")\n",
    "all_spotify = all_spotify.drop(all_spotify.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку\n",
    "\n",
    "frames = [all_spotify, spotify_curr_week]\n",
    "all_spotify = pd.concat(frames, sort=False)\n",
    "all_spotify.drop_duplicates(inplace = True) \n",
    "all_spotify.reset_index(inplace=True)\n",
    "all_spotify.drop(all_spotify.columns[[0]], axis=1, inplace=True)\n",
    "\n",
    "all_spotify.to_csv(\"all_spotify.csv\", encoding = \"utf-8\")\n",
    "\n",
    "now = datetime.now()\n",
    "print(now, \": updated all_spotify.csv with this week's chart.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
