{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данный скрипт: \n",
    "\n",
    "## - осуществляет парсинг еженедельного чарта Top Tracks Youtube \n",
    "### - через selenium\n",
    "\n",
    "## время запуска: утро воскресенья\n",
    "## период чарта: пятница-четверг\n",
    "\n",
    "## - на выходе:\n",
    "### - обновляет уже хранящиеся данные прошлых недель в csv \n",
    "### - сохраняет html файл актуального чарта для демонстрации на сайте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import datetime\n",
    "from datetime import datetime, date, time, timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import csv \n",
    "import json \n",
    "currentDT = datetime.now() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (from selenium) (1.25.9)\n",
      "Requirement already satisfied: chromedriver in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (2.24.1)\n"
     ]
    }
   ],
   "source": [
    "# установка и импорт selenium\n",
    "!pip install selenium\n",
    "from selenium import webdriver as wb\n",
    "!pip install chromedriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ПАРСИНГ: Youtube Top 100 Tracks Russia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium-код\n",
    "url='https://charts.youtube.com/charts/TopSongs/ru?hl=ru'\n",
    "br = wb.Chrome() \n",
    "br.get(url)\n",
    "sleep(randint(3,4))\n",
    "generated_html = br.page_source\n",
    "br.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# работаем с html\n",
    "soup = BeautifulSoup(generated_html, 'html.parser')\n",
    "\n",
    "all_together = soup.findAll('span', attrs={'class':'ytmc-ellipsis-text style-scope'})\n",
    "songs = all_together[2:][0::2]\n",
    "artists = all_together[2:][1::2]\n",
    "\n",
    "songs_clean = [i.get_text() for i in songs]\n",
    "artists_clean = [i.get_text() for i in artists]\n",
    "\n",
    "\n",
    "views = soup.findAll('span', attrs={'class':'style-scope ytmc-chart-table'})[4::5]\n",
    "views_clean = [i.get_text() for i in views]\n",
    "\n",
    "youtube_tracks_top_100 = pd.DataFrame()\n",
    "youtube_tracks_top_100['title'] = songs_clean\n",
    "youtube_tracks_top_100['artist'] = artists_clean\n",
    "youtube_tracks_top_100['streams'] = views_clean\n",
    "youtube_tracks_top_100['rank'] = youtube_tracks_top_100.reset_index().index +1\n",
    "youtube_tracks_top_100= youtube_tracks_top_100[['rank', 'title', 'artist', 'streams']]\n",
    "#date = дата скрейпинга!\n",
    "youtube_tracks_top_100[\"date\"] = currentDT.strftime(\"%d/%m/%Y\")  \n",
    "\n",
    "# записываем неделю \n",
    "date_start = currentDT - relativedelta(days=+7)\n",
    "date_end = currentDT - relativedelta(days=+1)\n",
    "week = datetime.strftime(date_start,\"%d/%m/%y\") + \" - \" + datetime.strftime(date_end,\"%d/%m/%y\")\n",
    "youtube_tracks_top_100[\"week\"] = week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ФОРМИРУЕМ ПОЛНЫЙ ЧАРТ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для подсчета количества недель, которые песня держится в чарте\n",
    "\n",
    "def weeks_in_chart(weekly_charts):\n",
    "    \n",
    "    df = weekly_charts\n",
    "    df[\"full_id\"] = df[\"title\"]+\"#bh#_#bh#\"+df[\"artist\"] # кодируем песню, чтобы избежать путаницы с одинаковыми названиями\n",
    "\n",
    "    return_df = pd.DataFrame(columns = ['title', 'artist', \"weeks_in_chart\"])\n",
    "\n",
    "    for i in set(list(df[\"full_id\"])):\n",
    "        s_df = df[df[\"full_id\"]==i] # таблица с одной песней\n",
    "        n_of_w = len(s_df)\n",
    "        add_df = pd.DataFrame()\n",
    "        add_df[\"weeks_in_chart\"] = [n_of_w]\n",
    "        add_df[\"title\"] = i.split(\"#bh#_#bh#\")[0]\n",
    "        add_df[\"artist\"] = i.split(\"#bh#_#bh#\")[1]\n",
    "        return_df=return_df.append(add_df, ignore_index=True)\n",
    "        \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем функцию, которая считает best position in chart, weeks in chart, change in rank [vs previous week]\n",
    "\n",
    "def metrics_delta(chart):\n",
    "    \n",
    "    #### best position\n",
    "    chart[\"rank\"] = chart[\"rank\"].astype(int)\n",
    "    best_pos = pd.DataFrame(chart.groupby(['title', 'artist']).agg({'rank' : 'min'}))\n",
    "    best_pos.reset_index(inplace=True)\n",
    "    best_pos.columns = ['title', 'artist', 'best_pos']\n",
    "    best_pos[\"best_pos\"] = best_pos[\"best_pos\"].astype('Int64') \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### change in rank vs previous week\n",
    "    \n",
    "    chart_last_week = chart.loc[chart['week'] == chart['week'].values[-1]] # назначаем  последнюю неделю\n",
    "    chart_dropped  = chart.drop(chart[chart['week'] == chart['week'].values[-1]].index)\n",
    "    \n",
    "    # назначаем предыдущую неделю\n",
    "    if len(chart_dropped) == 0:\n",
    "        chart_previous_week = chart.loc[chart['week'] == chart['week'].values[1]]\n",
    "    else: chart_previous_week = chart_dropped.loc[chart_dropped['week'] == chart_dropped['week'].values[-1]]\n",
    "    \n",
    "    \n",
    "    chart_previous_week = chart_previous_week[['title', 'artist', 'rank']]\n",
    "    # ! chart_upd - данные по последней неделе\n",
    "    chart_upd = pd.merge(chart_last_week, chart_previous_week, how='left', on=['title', 'artist']) \n",
    "    chart_upd['delta_rank'] = (chart_upd['rank_y'] - chart_upd['rank_x']).astype('Int64') \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #number of weeks in chart (use weeks_in_chart() function)\n",
    "    chart_upd.drop(\"weeks_in_chart\", 1, inplace = True) #avoid duplicates in columns\n",
    "    chart_upd = pd.merge(chart_upd, weeks_in_chart(chart), how='left', on=['title', 'artist'])\n",
    "    \n",
    "    \n",
    "    # присоединяем данные о best_pos \n",
    "    chart_upd.drop(\"best_pos\", 1, inplace=True)\n",
    "    new_chart = pd.merge(chart_upd, best_pos, how='left', on=['title', 'artist'])\n",
    "    chart_last_week = new_chart.loc[new_chart['week'] == new_chart['week'].values[-1]]\n",
    "    \n",
    "    # чистим\n",
    "    chart_last_week = chart_last_week.rename(columns={'rank_x': 'rank'})\n",
    "    chart_last_week.drop('rank_y', 1, inplace=True)\n",
    "    \n",
    "    \n",
    "    return chart_last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streams_delta_yout(chart):\n",
    "    \n",
    "    chart['streams'] = chart['streams'].replace({'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(int)\n",
    "    chart_last_week = chart[chart['week'] == chart['week'].values[-1]]\n",
    "    chart_dropped  = chart.drop(chart[chart['week'] == chart['week'].values[-1]].index)\n",
    "    \n",
    "    if len(chart_dropped) == 0:\n",
    "        chart_previous_week = chart.loc[chart['week'] == chart['week'].values[1]]\n",
    "    else: chart_previous_week = chart_dropped.loc[chart_dropped['week'] == chart_dropped['week'].values[-1]]\n",
    "        \n",
    "    chart_previous_week = chart_previous_week[['title', 'artist', 'streams']]\n",
    "    chart_upd = pd.merge(chart_last_week, chart_previous_week, how='left', on=['title', 'artist'])\n",
    "    chart_upd[\"streams_y\"].fillna(0, inplace=True)\n",
    "    chart_upd['delta_streams'] = (chart_upd['streams_x'] - chart_upd['streams_y']).astype('Int64')\n",
    "    chart_upd = chart_upd[['title', 'artist', 'delta_streams']]\n",
    "    \n",
    "    return chart_upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# соединяем старые данные с новыми\n",
    "all_youtube = pd.read_csv(\"all_youtube.csv\")\n",
    "all_youtube = all_youtube.drop(all_youtube.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_youtube, youtube_tracks_top_100] \n",
    "all_youtube = pd.concat(frames, sort=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count change in streams\n",
    "y1 = streams_delta_yout(all_youtube)\n",
    "\n",
    "# считаем остальные доп показатели\n",
    "youtube_curr_week = metrics_delta(all_youtube)\n",
    "\n",
    "youtube_curr_week.drop(\"delta_streams\", 1, inplace=True) #drop so that columns don't duplicate\n",
    "#merge delta_streams and other metrics\n",
    "youtube_curr_week = pd.merge(youtube_curr_week, y1, how='left', on=['title', 'artist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ЭКСПОРТ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORT TO JSON\n",
    "with open('current_youtube_json.json', 'w', encoding='utf-8') as file:\n",
    "    youtube_curr_week.to_json(file, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORT TO HTML\n",
    "# сохраняем html для использования на сайте (т.е. через Make_weekly_charts.py впоследствии)\n",
    "youtube_curr_week_html=youtube_curr_week[[\"rank\", \"delta_rank\", \"best_pos\", \"title\", \"artist\", \"streams\", \"delta_streams\", \"weeks_in_chart\", \"week\"]]\n",
    "youtube_curr_week_html.columns = [\"Позиция\", \"Изменение позиции\", \"Лучшая позиция\", \"Название\", \"Артист\", \"Прослушивания\", \"Динамика прослушиваний\", \"Недель в чарте\", \"Неделя\"]\n",
    "youtube_curr_week_html.to_html(\"current_youtube_html.html\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORT TO CSV - (i.e. TO THE MAIN DATABASE)\n",
    "# берем имеющийся в корневой директории csv файл и обновляем его\n",
    "\n",
    "all_youtube = pd.read_csv(\"all_youtube.csv\")\n",
    "all_youtube = all_youtube.drop(all_youtube.columns[[0]], axis=1) # удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_youtube, youtube_curr_week]\n",
    "all_youtube = pd.concat(frames, sort=False)\n",
    "all_youtube.to_csv(\"all_youtube.csv\", encoding = \"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
