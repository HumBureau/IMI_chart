{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#данный скрипт: \n",
    "\n",
    "## - должен запускаться каждый день один раз в сутки\n",
    "## - осуществляет парсинг ежедневных чартов\n",
    "### - через API: Deezer\n",
    "### - через requests: Apple Music, Yandex\n",
    "### - через selenium: VK\n",
    "\n",
    "## - на выходе:\n",
    "### - обновляет уже хранящиеся данные в csv файлах каждого стриминга, лежащие в корневой директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (from selenium) (1.25.9)\n",
      "Requirement already satisfied: chromedriver in /Users/sergey/opt/anaconda3/lib/python3.8/site-packages (2.24.1)\n"
     ]
    }
   ],
   "source": [
    "#установка и импорт selenium\n",
    "!pip install selenium\n",
    "from selenium import webdriver as wb\n",
    "!pip install chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#задаем команду для получения даты\n",
    "currentDT = datetime.datetime.now() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# технический код, созданный для момента, когда не было исходных файлов в директории\n",
    "#for i in [\"vk\", \"apple\", \"deezer\", \"yandex\"]:\n",
    "#    cols = ['rank', 'title', 'artist', \"date\"]\n",
    "#    name = \"all_\" + i + \".csv\" \n",
    "#    pd.DataFrame(columns = cols).to_csv(name, encoding= \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deezer Russia Top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "request_deezer = requests.get('https://api.deezer.com/playlist/1116189381') #ссылка на постоянный плейлист\n",
    "deezer_chart_json = request_deezer.json() #через API получаем json \n",
    "deezer_top_100_daily = pd.DataFrame(deezer_chart_json['tracks']['data']) #выбираем только список треков\n",
    "artists_deezer_top = [] #поскольку имена артистов \"запакованы\", осуществляем распаковку через цикл и заново приклеиваем к датафрейму\n",
    "for i in range(0, 100):\n",
    "    artists_deezer_top.append(deezer_chart_json['tracks']['data'][i]['artist']['name'])\n",
    "deezer_top_100_daily['artist'] = artists_deezer_top\n",
    "deezer_top_100_daily['rank'] = deezer_top_100_daily.reset_index().index +1 \n",
    "deezer_top_100_daily = deezer_top_100_daily[['rank', 'title', 'artist']]\n",
    "deezer_top_100_daily[\"date\"] = currentDT.strftime(\"%d/%m/%Y\")  \n",
    "\n",
    "# чарт этого дня готов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#берем имеющийся в корневой директории csv файл и обновляем его\n",
    "\n",
    "all_deezer = pd.read_csv(\"all_deezer.csv\")\n",
    "all_deezer = all_deezer.drop(all_deezer.columns[[0]], axis=1) #удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_deezer, deezer_top_100_daily]\n",
    "all_deezer = pd.concat(frames, sort=False)\n",
    "all_deezer.to_csv(\"all_deezer.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://music.apple.com/us/playlist/top-100-russia/pl.728bd30a9247487c80a483f4168a9dcd'\n",
    "r = requests.get(base_url)\n",
    "sleep(randint(1,3))\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "table = soup.findAll('div', attrs={'class':'header-and-songs-list'})\n",
    "songs = soup.findAll('div', attrs={'class':'song-name typography-label'})\n",
    "artists = soup.findAll('div', attrs={'class':'by-line typography-caption'})\n",
    "\n",
    "#чистим названия треков\n",
    "songs_clean = BeautifulSoup(str(songs), \"lxml\").text.split(\", \\n\")\n",
    "new_l=[]\n",
    "for i in songs_clean:\n",
    "    v = i.replace(\"\\n\", \"\")\n",
    "    v = v.replace(\"[\", \"\")\n",
    "    v = v.replace(\"]\", \"\")\n",
    "    v = v.strip(\" \")\n",
    "    new_l.append(v)\n",
    "songs_clean = new_l\n",
    "\n",
    "\n",
    "#чистим названия артистов\n",
    "artists_clean = BeautifulSoup(str(artists), \"lxml\").text.split(\"\\n, \\n\")\n",
    "new_l=[]\n",
    "for i in artists_clean:\n",
    "    v = i.replace(\"\\n\", \"\")\n",
    "    v = v.replace(\"[\", \"\")\n",
    "    v = v.replace(\"]\", \"\")\n",
    "    v = v.strip(\" \")\n",
    "    new_l.append(v)\n",
    "artists_clean = new_l\n",
    "\n",
    "apple_music_top_100_daily = pd.DataFrame()\n",
    "apple_music_top_100_daily['title'] = songs_clean\n",
    "apple_music_top_100_daily['artist'] = artists_clean\n",
    "\n",
    "apple_music_top_100_daily['rank'] = apple_music_top_100_daily.reset_index().index +1\n",
    "apple_music_top_100_daily = apple_music_top_100_daily[['rank', 'title', 'artist']]\n",
    "apple_music_top_100_daily[\"date\"] = currentDT.strftime(\"%d/%m/%Y\")  #добавляем дату\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#берем имеющийся в корневой директории csv файл и обновляем его\n",
    "\n",
    "all_apple = pd.read_csv(\"all_apple.csv\")\n",
    "all_apple = all_apple.drop(all_apple.columns[[0]], axis=1) #удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_apple, apple_music_top_100_daily]\n",
    "all_apple = pd.concat(frames, sort=False)\n",
    "all_apple.to_csv(\"all_apple.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yandex Музыка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#базовая ссылка на последний актуальный ежедневный чарт по России\n",
    "base_url = 'https://music.yandex.ru/chart'\n",
    "r = requests.get(base_url)\n",
    "#на всякий случай поставим на паузу\n",
    "sleep(randint(1,3))\n",
    "\n",
    "#находим в верстке сайта интересующие нас части\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "songs = soup.findAll('div', attrs={'class':'d-track__name'})\n",
    "artists = soup.findAll('span', attrs={'class':'d-track__artists'})\n",
    "\n",
    "#делаем список вторичных названий песен (слов вроде remix, cover, и тд), чтобы они не сливались с названиями \n",
    "sec_titles = soup.findAll('span', attrs={'class':'d-track__version deco-typo-secondary'})\n",
    "sec_titles_clean = [i.get_text() for i in sec_titles]\n",
    "sec_titles_clean = sorted(sec_titles_clean, reverse=True, key=len)\n",
    "\n",
    "#чистим названия песен и артистов\n",
    "songs_clean = [i.get_text() for i in songs]\n",
    "new_l=[]\n",
    "for i in songs_clean:\n",
    "    for j in sec_titles_clean:\n",
    "        if j in i:\n",
    "            v = i.replace(j, \" (\"+j+\")\")\n",
    "            break\n",
    "        else:\n",
    "            v = i\n",
    "    new_l.append(v)\n",
    "songs_clean = new_l\n",
    "artists_clean = [i.get_text() for i in artists]\n",
    "\n",
    "yandex_music_top_100_daily = pd.DataFrame()\n",
    "yandex_music_top_100_daily['title'] = songs_clean\n",
    "yandex_music_top_100_daily['artist'] = artists_clean\n",
    "yandex_music_top_100_daily['rank'] = yandex_music_top_100_daily.reset_index().index +1\n",
    "yandex_music_top_100_daily= yandex_music_top_100_daily[['rank', 'title', 'artist']]\n",
    "yandex_music_top_100_daily[\"date\"] = currentDT.strftime(\"%d/%m/%Y\")  \n",
    "\n",
    "\n",
    "# чарт этого дня готов\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#берем имеющийся в корневой директории csv файл и обновляем его\n",
    "\n",
    "all_yandex = pd.read_csv(\"all_yandex.csv\")\n",
    "all_yandex = all_yandex.drop(all_yandex.columns[[0]], axis=1) #удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_yandex, yandex_music_top_100_daily]\n",
    "all_yandex = pd.concat(frames, sort=False)\n",
    "all_yandex.to_csv(\"all_yandex.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите логин: diplodok.95@mail.ru\n",
      "Введите пароль: aintthateasy\n"
     ]
    }
   ],
   "source": [
    "#selenium-часть\n",
    "url='https://vk.com'\n",
    "br = wb.Chrome(\"/Users/sergey/chromedriver\") #заменить на директорию, в которой лежит нужный драйвер \n",
    "br.get(url)\n",
    "sleep(randint(2,4))\n",
    "e_mail_window = br.find_element_by_css_selector(\"#index_email\")\n",
    "password_window = br.find_element_by_css_selector(\"#index_pass\")\n",
    "login_vk = input('Введите логин: ') #изменить при дальнейшем использовании на специально зарегистрированного пользователя? \n",
    "password_vk = input('Введите пароль: ') #изменить при использовании (см выше)\n",
    "e_mail_window.send_keys(login_vk)\n",
    "password_window.send_keys(password_vk)\n",
    "button1 = br.find_element_by_xpath('//*[(@id = \"index_login_button\")]')\n",
    "button1.click()\n",
    "sleep(randint(19,20))\n",
    "button2 = br.find_element_by_xpath('//*[(@id = \"l_aud\")]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"fl_l\", \" \" ))]')\n",
    "button2.click()\n",
    "sleep(randint(4,5))\n",
    "button3 = br.find_element_by_css_selector('div#content li._audio_section_tab__explore > a')\n",
    "button3.click()\n",
    "sleep(randint(4,5))\n",
    "button4 = br.find_element_by_css_selector('div#content div.CatalogBlock__recoms_top_audios_global_header.CatalogBlock__header > div > a')\n",
    "button4.click()\n",
    "sleep(randint(10,11))\n",
    "soup = BeautifulSoup(br.page_source)\n",
    "br.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#работаем с html\n",
    "\n",
    "songs = soup.findAll('span', attrs={'class':\"audio_row__title_inner _audio_row__title_inner\"})\n",
    "artists = soup.findAll('div', attrs={'class':\"audio_row__performers\"})\n",
    "\n",
    "songs_clean = [i.get_text() for i in songs]\n",
    "artists_clean = [i.get_text() for i in artists]\n",
    "\n",
    "data = {\"rank\": [i for i in range(1, 101)], \"title\": songs_clean, \"artist\":artists_clean}\n",
    "vk_music_top_100_daily = pd.DataFrame(data)\n",
    "vk_music_top_100_daily[\"date\"] = currentDT.strftime(\"%d/%m/%Y\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#берем имеющийся в корневой директории csv файл и обновляем его\n",
    "\n",
    "all_vk = pd.read_csv(\"all_vk.csv\")\n",
    "all_vk = all_vk.drop(all_vk.columns[[0]], axis=1) #удаляем получающуюся после импорта лишнюю колонку \n",
    "frames = [all_vk, vk_music_top_100_daily]\n",
    "all_vk = pd.concat(frames, sort=False)\n",
    "all_vk.to_csv(\"all_vk.csv\", encoding = \"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
