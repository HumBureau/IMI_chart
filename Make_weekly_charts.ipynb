{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#данный скрипт:\n",
    "## - высчитывает еженедельные чарты стримингов, усредняя ежедневные чарты за 7 дней \n",
    "## - стриминги: Apple Music, VK, Deezer, Yandex\n",
    "## - должен запускаться один раз в неделю ранним утром пятницы после Weekly_parsing.py\n",
    "\n",
    "## соединяет получающиеся чарты в единый html файл для публикации на сайте (включая \"настоящие\" еженедельные чарты)\n",
    "\n",
    "#на выходе:\n",
    "## - обновляет csv файлы с соответствующими еженедельными чартами 4-x стримингов\n",
    "## - сохраняет в корневую директорию html файлы с новыми еженедельными чартами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import datetime\n",
    "from datetime import datetime, date, time, timezone\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#задаем команду для получения даты\n",
    "currentDT = datetime.datetime.now() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# технический код, созданный для момента, когда не было исходных файлов в директории\n",
    "#for i in [\"vk\", \"apple\", \"deezer\", \"yandex\"]:\n",
    "#    cols = ['rank', 'title', 'artist', \"week\", \"raw_rank\"]\n",
    "#    name = \"all_\" + i + \"_weekly.csv\" \n",
    "#    pd.DataFrame(columns = cols).to_csv(name, encoding= \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загружаем полные базы данных по всем ежедневным чартам\n",
    "all_vk = pd.read_csv(\"all_vk.csv\")\n",
    "all_yandex = pd.read_csv(\"all_yandex.csv\")\n",
    "all_deezer = pd.read_csv(\"all_deezer.csv\")\n",
    "all_apple = pd.read_csv(\"all_apple.csv\")\n",
    "\n",
    "#удаляем получающуюся после импорта лишнюю колонку \n",
    "all_charts= [all_apple, all_deezer, all_vk, all_yandex]\n",
    "for i in all_charts:\n",
    "    i.drop(i.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения недельного чарта через усреднение ежедневных\n",
    "\n",
    "#заменяем номер строчки на X в те дни, когда трека нет в чарте \n",
    "# X в будущем должен оцениваться с использованием данных других стримингов (особенно спотифай)\n",
    "## пока что X - константа.\n",
    "\n",
    "def average(df, X):\n",
    "    \n",
    "    df['Datetime'] = [datetime.strptime(i, \"%d/%m/%Y\") for i in df[\"date\"]]\n",
    "    \n",
    "    #take last week only\n",
    "    date_start = currentDT - relativedelta(days=+7)\n",
    "    date_end = currentDT - relativedelta(days=+1)\n",
    "    last_week_df = df[date_start <= df[\"Datetime\"]]\n",
    "    df = last_week_df\n",
    "    \n",
    "    raw_rank = []\n",
    "    songs =[]\n",
    "    artists = []\n",
    "    for i in list(set(df[\"title\"])):\n",
    "        newdf = df[df[\"title\"]==i]\n",
    "        for j in list(set(newdf[\"artist\"])):\n",
    "            one_track_df = newdf[newdf[\"artist\"]==j]\n",
    "            #how many missing days?\n",
    "            miss_days = 7 - len(one_track_df)\n",
    "            average_rank = (sum(one_track_df[\"rank\"]) + miss_days*(X)) / 7  #считаем среднюю строчку трека (использование X)\n",
    "            songs.append(i)\n",
    "            artists.append(j)\n",
    "            raw_rank.append(average_rank)\n",
    "\n",
    "    data = {\"raw_rank\": raw_rank, \"title\": songs, \"artist\": artists}        \n",
    "    new_chart = pd.DataFrame(data)\n",
    "    new_chart.sort_values(by=['raw_rank'], inplace=True)\n",
    "\n",
    "    new_chart['rank'] = new_chart.reset_index().index +1\n",
    "    new_chart.reset_index(inplace=True)\n",
    "    week = datetime.strftime(date_start,\"%d/%m/%y\") + \" - \" + datetime.strftime(date_end,\"%d/%m/%y\")\n",
    "    new_chart[\"week\"] = week\n",
    "    \n",
    "    new_chart = new_chart[['rank', 'title', 'artist', \"week\", \"raw_rank\"]]\n",
    "    \n",
    "    #округляем raw_rank\n",
    "    new_chart[\"raw_rank\"] = round(new_chart[\"raw_rank\"], 3)\n",
    "    \n",
    "    return new_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#просто техническая функция для отображения изначальных имен чартов\n",
    "def name_of_global_obj(xx):\n",
    "    return [objname for objname, oid in globals().items()\n",
    "            if id(oid)==id(xx)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выполняем функцию average() и обновляем имеющиеся еженедельные чарты из csv в корне\n",
    "\n",
    "for c in all_charts:\n",
    "    output_chart = average(c, 150)\n",
    "    name_of_chart = str(name_of_global_obj(c)) \n",
    "    \n",
    "    #сохраняем чарт в HTML\n",
    "    platform_name = name_of_chart.replace(\"all_\", \"\")\n",
    "    html_name = \"current_\"+platform_name+\"_html.html\"\n",
    "    output_chart.to_html(html_name, encoding = \"utf-8\")\n",
    "    \n",
    "    #переходим к загрузке имеющегося csv c предыдущими еженедельными чартами\n",
    "    name_of_weekly_chart = name_of_chart +\"_weekly.csv\"\n",
    "    old_csv = pd.read_csv(name_of_weekly_chart)\n",
    "    \n",
    "    old_csv = old_csv.drop(old_csv.columns[[0]], axis=1) #удаляем получающуюся после импорта лишнюю колонку \n",
    "    frames = [old_csv, output_chart]\n",
    "    new_csv = pd.concat(frames, sort=False)\n",
    "    new_csv.to_csv(name_of_weekly_chart, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### создание финального HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "\n",
    "h1 = pd.DataFrame({'Spotify Weekly Top 200' : '-'}, index=[0])\n",
    "h2 = pd.DataFrame({'Youtube Top 100 Tracks' : '-'}, index=[0])\n",
    "h3 = pd.DataFrame({'Apple Music Top 100 -- by IMI' : '-'}, index=[0])\n",
    "h4 = pd.DataFrame({'Yandex Music Top 100 -- by IMI' : '-'}, index=[0])\n",
    "h5 = pd.DataFrame({'Deezer Top 100 -- by IMI' : '-'}, index=[0])\n",
    "h6 = pd.DataFrame({'VK/BOOM Top 100 -- by IMI' : '-'}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#открываем html спотифая и ютуба из корневой директории (туда они сохранены weekly_parsing.py)\n",
    "l.append(h1.to_html())\n",
    "with open('current_spotify_html.html', 'r') as f:\n",
    "    l.append(f.read())\n",
    "    \n",
    "l.append(h2.to_html())\n",
    "with open('current_youtube_html.html', 'r') as f:\n",
    "    l.append(f.read())\n",
    "    \n",
    "l.append(h3.to_html())\n",
    "with open('current_apple_html.html', 'r') as f:\n",
    "    l.append(f.read())\n",
    "    \n",
    "l.append(h4.to_html())\n",
    "with open('current_yandex_html.html', 'r') as f:\n",
    "    l.append(f.read())\n",
    "    \n",
    "l.append(h5.to_html())\n",
    "with open('current_deezer_html.html', 'r') as f:\n",
    "    l.append(f.read())\n",
    "    \n",
    "l.append(h6.to_html())\n",
    "with open('current_vk_html.html', 'r') as f:\n",
    "    l.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраняем итоговый html\n",
    "final_html = ''.join(l)\n",
    "with open(\"current_full_html.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(final_html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
